{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf913d0",
   "metadata": {},
   "source": [
    "Stable version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1814e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NZTA envelope-first optimiser – COPT (Fixed Funding + Piecewise Soft Cap) v94.14\n",
    "\n",
    "Hybrid of v94.11 (stable/fast defaults) and v94.13 (multi‑phase + Victory Lap).\n",
    "\n",
    "Key design:\n",
    "──────────────────────────────────\n",
    "1. THREADS / PARAM DEFAULTS (back to 94.11 behaviour):\n",
    "   - Force single-threaded BLAS / COPT by default for stability.\n",
    "   - COPT model init:\n",
    "       Threads     = 1\n",
    "       MipStartMode= 2\n",
    "       Presolve    = 1\n",
    "       Scaling     = 1\n",
    "\n",
    "2. PROFILE‑DEPENDENT SOLVE STRATEGY:\n",
    "\n",
    "   (a) fast, balanced  → Single-phase (v94.11 style)\n",
    "       - Just TimeLimit + RelGap\n",
    "       - Optional precision top-up to tighten gap if we already have an incumbent.\n",
    "\n",
    "   (b) thorough        → 2‑Phase (Probe + Verify + Victory Lap)\n",
    "       - Phase 1: Probe (≈10% of budget). Quick warm-up.\n",
    "       - Phase 2: Verify with dynamic Victory Lap:\n",
    "           • Callback monitors BestObj/BestBnd.\n",
    "           • When gap < target, start a 60s “Victory Lap” then stop.\n",
    "           • If gap never hits target, stop at the normal time limit.\n",
    "\n",
    "   (c) ultra           → 3‑Phase (Probe + Verify + Victory Lap + Grind)\n",
    "       - Phase 1: Probe (10%).\n",
    "       - Phase 2: Verify + Victory Lap (30%).\n",
    "           • If gap < target and Victory Lap completes → skip Phase 3.\n",
    "       - Phase 3: Grind with remaining time (up to full budget).\n",
    "\n",
    "   All phases *only* manipulate TimeLimit / RelGap; no aggressive heuristics or\n",
    "   exotic search controls – we let COPT do its job with the proven stable\n",
    "   defaults from v94.11.\n",
    "\n",
    "3. CALLBACK ROBUSTNESS:\n",
    "   - Uses coptpy.CallbackBase + getInfo(COPT.CbInfo.BestObj/BestBnd) to compute\n",
    "     gap inside the callback (no reliance on non-portable helpers).\n",
    "   - Auto‑detects callback context constants (MIPSOL / MIPNODE); falls back\n",
    "     gracefully to single‑phase solve if callbacks aren’t supported.\n",
    "\n",
    "4. BUGFIXES vs earlier three‑phase code:\n",
    "   - orchestrate_total no longer references non-existent res.best_solution_values.\n",
    "   - Victory Lap callback now uses getInfo instead of getBestGap/hasIncumbent.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# THREADING CONTROL\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Default: mimic v94.11 (single-threaded BLAS & COPT) for stability.\n",
    "FORCE_SINGLE_THREAD = False\n",
    "\n",
    "if FORCE_SINGLE_THREAD:\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "    # COPT respects both this env var and the 'Threads' model parameter.\n",
    "    os.environ[\"COPT_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import hashlib\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Iterable, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- COPT --------------------------------------------------------------------\n",
    "try:\n",
    "    import coptpy as co\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"coptpy is required. Please ensure COPT is installed and licensed \"\n",
    "        \"(pip install coptpy) and COPT_HOME is configured.\"\n",
    "    ) from e\n",
    "\n",
    "COPT = co.COPT\n",
    "\n",
    "# --- CALLBACK CONSTANT DISCOVERY --------------------------------------------\n",
    "def _get_copt_constant(names: List[str], default: int = 0) -> int:\n",
    "    \"\"\"\n",
    "    Try multiple possible constant names to support different COPT versions.\n",
    "    Returns 0 if none are found.\n",
    "    \"\"\"\n",
    "    for name in names:\n",
    "        if hasattr(COPT, name):\n",
    "            return getattr(COPT, name)\n",
    "    return default\n",
    "\n",
    "# Typical MIP callback contexts (names differ slightly across versions)\n",
    "CTX_MIPSOL = _get_copt_constant([\"CBC_MIP_SOL\", \"CB_MIPSOL\", \"MIPSOL\"], 0)\n",
    "CTX_MIPNODE = _get_copt_constant([\"CBC_MIP_NODE\", \"CB_MIPNODE\", \"MIPNODE\"], 0)\n",
    "\n",
    "if CTX_MIPSOL == 0 and CTX_MIPNODE == 0:\n",
    "    print(\n",
    "        \"Warning: Could not detect COPT MIP callback context constants. \"\n",
    "        \"Victory Lap callback may not be active.\"\n",
    "    )\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# PATHS\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "ROOT = Path(r\"C:\\Users\\Adrian Desilvestro\\Documents\\NZTA\\Project_Rons_optimisation\")\n",
    "DATA_FILE = ROOT / \"Cost_benefit_streams.xlsx\"\n",
    "CACHE = ROOT / \"scenario_cache_benefit_mo\"\n",
    "CACHE.mkdir(exist_ok=True)\n",
    "PKL_PREFIX: str | None = \"mathematical best_RONS_\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# CALENDAR / ECON\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "START_FY = 2026\n",
    "FINAL_YEAR = 2095\n",
    "TFIXED = int(FINAL_YEAR - START_FY + 1)\n",
    "YEARS = TFIXED\n",
    "\n",
    "BENEFIT_DISCOUNT_RATE = 0.02\n",
    "\n",
    "# Scaling: 1 unit of spend in the model = 0.01 M (10k)\n",
    "SPEND_SCALE = 100       # 1 unit = 0.01 M\n",
    "PV_SCALE = 10000        # integer PV scaling\n",
    "\n",
    "MAX_STARTS_PER_FY = 100  # Max project starts allowed in a single year\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# FUNDING ENVELOPE CONFIGURATION\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "TAPER_YEARS = 0\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# PIECEWISE SOFT CAP SETTINGS (The \"Tax Brackets\")\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "PIECEWISE_CAP_TIERS: List[Tuple[float, float]] = [\n",
    "    (0.12, 1000.0),\n",
    "    (0.15, 4000.0),\n",
    "    (0.20, 12000.0),\n",
    "]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# OBJECTIVE WEIGHTS\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "BACKLOG_WEIGHT = 1.0            # Penalise normal net balance\n",
    "PV_WEIGHT = 1e-4                # PV tie-breaker\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# SOLVER GLOBALS\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Match v94.11: one worker thread, deterministic seed.\n",
    "SOLVER_THREADS_DEFAULT = 0\n",
    "SOLVER_SEED_DEFAULT = 17\n",
    "VERBOSE = 2\n",
    "\n",
    "# Profile grid (time in seconds, target relative gap)\n",
    "OPTIMISATION_PROFILE = \"ultra\"  # \"fast\", \"balanced\", \"thorough\", \"ultra\"\n",
    "EFFORT: Dict[str, Dict[str, float]] = {\n",
    "    \"fast\":     {\"MO\": 60.0,  \"REL_GAP\": 0.020},\n",
    "    \"balanced\": {\"MO\": 120.0, \"REL_GAP\": 0.015},\n",
    "    # thorough: more time, tighter gap\n",
    "    \"thorough\": {\"MO\": 360.0, \"REL_GAP\": 0.003},  # 6m, 0.3%\n",
    "    # ultra: maximum rigour\n",
    "    \"ultra\":    {\"MO\": 900.0, \"REL_GAP\": 0.001},  # 15m, 0.1%\n",
    "}\n",
    "\n",
    "# Legacy tuning knobs from v94.11 (used in single‑phase solver)\n",
    "FAST_STOP_GAP = 0.007\n",
    "CONVERGENCE_REPEAT_N = 2\n",
    "PRECISION_TOPUP_TIME = 180.0\n",
    "PRECISION_TOPUP_GAP = 0.007\n",
    "SLOW_GAP_1 = 0.05\n",
    "SLOW_GAP_2 = 0.20\n",
    "\n",
    "VALIDATE_SOLUTION = True\n",
    "VALIDATION_TOL_M = 1e-3\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# RUN PROFILE\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "COST_TYPES_RUN: List[str] = [\"P50 - Real\"]\n",
    "BENEFIT_SCENARIOS: Dict[str, str] = {\"LIN40\": \"Benefits Linear 40yrs\"}\n",
    "\n",
    "SURPLUS_OPTIONS_M: Dict[str, float] = {\"s1500\": 1500.0}#, \"s2000\": 2000.0}\n",
    "PLUSMINUS_LEVELS_M: List[float] = [0,250]\n",
    "\n",
    "# --- PROJECT CONSTRAINTS -----------------------------------------------------\n",
    "FORCED_START: Dict[str, Dict] = {\n",
    "    # \"Project A\": {\"start\": 2028, \"include\": True},\n",
    "}\n",
    "\n",
    "MIN_START_YEAR: Dict[str, int] = {\n",
    "    # \"Project 1\": 2035,\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "PROJECT_SELECTION_MODE = \"auto\"\n",
    "WHITELIST_FALLBACK_TO_BLACKLIST_IF_EMPTY = True\n",
    "WARN_ON_UNMATCHED_RULE_NAMES = True\n",
    "DIMENSION_INCLUSIONS: Dict[str, bool] = {\n",
    "    \"Total\": True,\n",
    "    \"Healthy and safe people\": True,\n",
    "    \"Inclusive Access\": True,\n",
    "    \"Environmental Sustainability\": True,\n",
    "    \"Economic Prosperity\": True,\n",
    "    \"Resilience and Security\": True,\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# MONOTONE PV GUARD BETWEEN BUFFERS\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "ENFORCE_MONOTONE_PV_ACROSS_BUFFERS = True\n",
    "MONO_REL_EPS = 1e-4\n",
    "MONO_ABS_EPS = 1e-3\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# LOGGING / HELPERS\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def cal_years(ny: int) -> List[int]:\n",
    "    return [START_FY + i for i in range(ny)]\n",
    "\n",
    "def clean(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s or \"\").replace(\"\\xa0\", \" \")).strip()\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return clean(s).lower()\n",
    "\n",
    "def iround(x: float, scale: float) -> int:\n",
    "    return int(round(float(x) * float(scale)))\n",
    "\n",
    "def _log(msg: str) -> None:\n",
    "    if VERBOSE >= 1:\n",
    "        print(msg)\n",
    "\n",
    "class ParamChangeLogger:\n",
    "    def __init__(self):\n",
    "        self._last_params: Dict[str, Any] = {}\n",
    "\n",
    "    def log_changes(self, params: Dict[str, Any], header: str = \"Param changes\") -> None:\n",
    "        changed = {\n",
    "            k: v\n",
    "            for k, v in params.items()\n",
    "            if k not in self._last_params or self._last_params[k] != v\n",
    "        }\n",
    "        if changed:\n",
    "            self._last_params.update(params)\n",
    "            changed_str = \", \".join(\n",
    "                f\"{k}={repr(v)}\" for k, v in sorted(changed.items())\n",
    "            )\n",
    "            print(f\"{header}: {changed_str}\")\n",
    "\n",
    "_PARAM_LOGGER = ParamChangeLogger()\n",
    "\n",
    "def _apply_params_logged(m: co.Model, updates: Dict[str, Any], header: str) -> None:\n",
    "    _PARAM_LOGGER.log_changes(updates, header=header)\n",
    "    for k, v in updates.items():\n",
    "        try:\n",
    "            m.setParam(k, v)\n",
    "        except Exception:\n",
    "            # Silently ignore unknown/obsolete parameters on this COPT version.\n",
    "            pass\n",
    "\n",
    "def _has_incumbent(m: co.Model) -> bool:\n",
    "    try:\n",
    "        hm = m.getAttr(COPT.Attr.HasMipSol)\n",
    "        if hm is not None:\n",
    "            return bool(hm)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        m.getAttr(COPT.Attr.ObjVal)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _best_gap(m: co.Model) -> Optional[float]:\n",
    "    \"\"\"Best known relative MIP gap (fraction, not percent, if available).\"\"\"\n",
    "    try:\n",
    "        g = m.getAttr(COPT.Attr.BestGap)\n",
    "        if g is not None:\n",
    "            return float(g)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        obj = float(m.getAttr(COPT.Attr.ObjVal))\n",
    "        bnd = float(m.getAttr(COPT.Attr.BestBnd))\n",
    "        denom = max(1.0, abs(obj))\n",
    "        return abs(bnd - obj) / denom\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "RUN_ID = hashlib.sha1(\n",
    "    f\"{OPTIMISATION_PROFILE}|{SOLVER_SEED_DEFAULT}|{SOLVER_THREADS_DEFAULT}\".encode(\n",
    "        \"utf-8\"\n",
    "    )\n",
    ").hexdigest()[:8]\n",
    "\n",
    "def _val(val_by_id: Optional[Dict[int, float]], var: \"co.Var\") -> float:\n",
    "    try:\n",
    "        if val_by_id is not None:\n",
    "            v = val_by_id.get(id(var), None)\n",
    "            if v is not None:\n",
    "                return float(v)\n",
    "        return float(var.X)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def _now_stamp() -> str:\n",
    "    return time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "\n",
    "def pkl_save(path: Path, payload: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Save payload to pickle and log a one-line summary including final gap (%)\n",
    "    where available.\n",
    "    \"\"\"\n",
    "    with path.open(\"wb\") as f:\n",
    "        pickle.dump(payload, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    size = path.stat().st_size if path.exists() else 0\n",
    "    objective = payload.get(\"objective\", payload.get(\"primary_dim\", \"?\"))\n",
    "    best = payload.get(\"best\", {}) or {}\n",
    "    pv = best.get(\"pv\", payload.get(\"pv_total\", \"?\"))\n",
    "\n",
    "    gap_frac = best.get(\"gap\", payload.get(\"gap\", None))\n",
    "    gap_pct_val = best.get(\"gap_pct\", payload.get(\"gap_pct\", None))\n",
    "\n",
    "    gap_str: str\n",
    "    if isinstance(gap_pct_val, (int, float)):\n",
    "        gap_str = f\"{gap_pct_val:.4f}%\"\n",
    "    elif isinstance(gap_frac, (int, float)):\n",
    "        gap_str = f\"{gap_frac * 100.0:.4f}%\"\n",
    "    else:\n",
    "        gap_str = \"?\"\n",
    "\n",
    "    print(\n",
    "        f\"Saved: {path} ({size} bytes) \"\n",
    "        f\"objective={objective} pv={pv} gap={gap_str}\"\n",
    "    )\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# I/O – Costs & Benefits\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def load_costs(cost_type: str):\n",
    "    df = pd.read_excel(DATA_FILE, sheet_name=\"Costs\", engine=\"openpyxl\")\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    proj_col = [c for c in df.columns if c.lower() == \"project\"]\n",
    "    if not proj_col:\n",
    "        raise RuntimeError(\"Costs sheet needs 'Project'.\")\n",
    "    proj_col = proj_col[-1]\n",
    "\n",
    "    horizon_all = [START_FY + i for i in range(YEARS)]\n",
    "    year_cols = {int(c): c for c in df.columns if str(c).isdigit()}\n",
    "    use_cols = [year_cols.get(y, None) for y in horizon_all]\n",
    "\n",
    "    cut = df[df[\"Cost type\"].astype(str).str.strip() == str(cost_type).strip()].copy()\n",
    "    costs_input: Dict[str, List[float]] = {}\n",
    "    for _, r in cut.iterrows():\n",
    "        p = clean(r[proj_col])\n",
    "        vals = [\n",
    "            (pd.to_numeric(r[c], errors=\"coerce\") if c is not None else 0.0)\n",
    "            for c in use_cols\n",
    "        ]\n",
    "        costs_input[p] = (pd.Series(vals).fillna(0.0) / 1_000_000.0).tolist()  # M\n",
    "\n",
    "    projects: Dict[str, Dict[str, Any]] = {}\n",
    "    variants: Dict[str, Dict[str, Any]] = {}\n",
    "    for p, seriesM in costs_input.items():\n",
    "        s = pd.Series(seriesM)\n",
    "        nz = s.to_numpy().nonzero()[0]\n",
    "        if nz.size == 0:\n",
    "            continue\n",
    "        seg = s.iloc[nz.min() : nz.max() + 1].tolist()\n",
    "        projects[p] = {\"cost\": float(sum(seg)), \"dur\": len(seg), \"spend\": seg}\n",
    "        variants[p] = {\n",
    "            \"base\": p,\n",
    "            \"dur\": len(seg),\n",
    "            \"spend\": seg,\n",
    "            \"first_year_idx\": int(nz.min()),\n",
    "        }\n",
    "\n",
    "    costs_input_df = pd.DataFrame(costs_input, index=horizon_all).T\n",
    "    costs_input_df.index.name = \"Project\"\n",
    "    return projects, variants, costs_input_df\n",
    "\n",
    "def load_benefits(sheet: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = pd.read_excel(DATA_FILE, sheet_name=sheet, engine=\"openpyxl\")\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    if \"Project\" not in df.columns:\n",
    "        raise RuntimeError(\"Benefits sheet needs 'Project'.\")\n",
    "    dim_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower().startswith(\"dimension\"):\n",
    "            dim_col = c\n",
    "            break\n",
    "    if dim_col is None:\n",
    "        raise RuntimeError(\"Benefits sheet needs 'Dimension'.\")\n",
    "    if dim_col != \"Dimension\":\n",
    "        df.rename(columns={dim_col: \"Dimension\"}, inplace=True)\n",
    "\n",
    "    tcols: List[Tuple[int, str]] = []\n",
    "    for c in df.columns:\n",
    "        m = re.fullmatch(r\"[tT]\\s*\\+\\s*(\\d+)\", str(c))\n",
    "        if m:\n",
    "            tcols.append((int(m.group(1)), c))\n",
    "    tcols.sort(key=lambda x: x[0])\n",
    "\n",
    "    for _, c in tcols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    ben_kernel_df = df.copy()\n",
    "    ben_kernel_df[\"Project\"] = ben_kernel_df[\"Project\"].map(clean)\n",
    "    ben_kernel_df[\"Dimension\"] = ben_kernel_df[\"Dimension\"].map(clean)\n",
    "    ben_kernel_df.set_index([\"Project\", \"Dimension\"], inplace=True)\n",
    "    ben_kernel_df = ben_kernel_df[[c for _, c in tcols]]\n",
    "    return df, ben_kernel_df\n",
    "\n",
    "def map_benefit_kernels(benef_df: pd.DataFrame, variants: Dict[str, dict]):\n",
    "    tcols = [\n",
    "        c\n",
    "        for _, c in sorted(\n",
    "            [\n",
    "                (int(re.fullmatch(r\"[tT]\\s*\\+\\s*(\\d+)\", c).group(1)), c)\n",
    "                for c in benef_df.columns\n",
    "                if re.fullmatch(r\"[tT]\\s*\\+\\s*(\\d+)\", c)\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    df = benef_df.copy()\n",
    "    df[\"Project_clean\"] = df[\"Project\"].map(clean)\n",
    "    df[\"Dimension_clean\"] = df[\"Dimension\"].map(clean)\n",
    "\n",
    "    flows_by_dim: Dict[str, Dict[str, List[float]]] = {}\n",
    "    order: List[str] = []\n",
    "    for _, r in df.iterrows():\n",
    "        p = r[\"Project_clean\"]\n",
    "        d = r[\"Dimension_clean\"]\n",
    "        seq = r[tcols].to_numpy(dtype=float).tolist()\n",
    "        flows_by_dim.setdefault(d, {})[p] = seq\n",
    "        if d not in order:\n",
    "            order.append(d)\n",
    "\n",
    "    if \"Total\" not in flows_by_dim:\n",
    "        flows_by_dim[\"Total\"] = {}\n",
    "    all_dims = [d for d in order if d.lower() != \"total\"]\n",
    "    projs = set()\n",
    "    for d in all_dims:\n",
    "        projs |= set(flows_by_dim[d].keys())\n",
    "\n",
    "    for p in projs:\n",
    "        acc = None\n",
    "        for d in all_dims:\n",
    "            v = flows_by_dim[d].get(p)\n",
    "            if v is None:\n",
    "                continue\n",
    "            acc = v if acc is None else [a + b for a, b in zip(acc, v)]\n",
    "        flows_by_dim[\"Total\"][p] = acc or [0.0] * len(tcols)\n",
    "\n",
    "    if \"Total\" not in order:\n",
    "        order.append(\"Total\")\n",
    "\n",
    "    keeps = set(variants.keys())\n",
    "    for d in list(flows_by_dim.keys()):\n",
    "        flows_by_dim[d] = {p: seq for p, seq in flows_by_dim[d].items() if p in keeps}\n",
    "\n",
    "    kernels_by_dim: Dict[str, Dict[str, List[float]]] = {}\n",
    "    for d, mp_ in flows_by_dim.items():\n",
    "        kernels_by_dim[d] = {}\n",
    "        for v, meta in variants.items():\n",
    "            dur = meta[\"dur\"]\n",
    "            ker = mp_.get(v, [])\n",
    "            kernels_by_dim[d][v] = [0.0] * dur + [float(x) for x in ker]\n",
    "    return order, kernels_by_dim\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Rules / Starts\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def apply_forced_rules(variants: Dict[str, dict], rules: Dict[str, Dict]):\n",
    "    v_norm2canon = {norm(v): v for v in variants.keys()}\n",
    "    v_norm_set = set(v_norm2canon.keys())\n",
    "    include_true_norm, exclude_true_norm = set(), set()\n",
    "    start_map_all_norm: Dict[str, int] = {}\n",
    "\n",
    "    for raw_name, spec in (rules or {}).items():\n",
    "        pname_norm = norm(raw_name)\n",
    "        inc = spec.get(\"include\", None)\n",
    "        st = spec.get(\"start\", None)\n",
    "        if inc is True:\n",
    "            include_true_norm.add(pname_norm)\n",
    "        if inc is False:\n",
    "            exclude_true_norm.add(pname_norm)\n",
    "        if st is not None:\n",
    "            start_map_all_norm[pname_norm] = int(st)\n",
    "\n",
    "    matched_includes_norm = include_true_norm & v_norm_set\n",
    "    mode_req = (PROJECT_SELECTION_MODE or \"auto\").strip().lower()\n",
    "\n",
    "    has_include_true_rules = len(include_true_norm) > 0\n",
    "    use_whitelist = (mode_req == \"whitelist\") or (\n",
    "        mode_req == \"auto\" and has_include_true_rules\n",
    "    )\n",
    "\n",
    "    if use_whitelist:\n",
    "        keep_norm = matched_includes_norm\n",
    "        mode = \"WHITELIST\"\n",
    "    else:\n",
    "        if len(matched_includes_norm) == 0 and WHITELIST_FALLBACK_TO_BLACKLIST_IF_EMPTY:\n",
    "            keep_norm = v_norm_set - (exclude_true_norm & v_norm_set)\n",
    "            mode = \"BLACKLIST (fallback)\"\n",
    "        else:\n",
    "            keep_norm = v_norm_set - (exclude_true_norm & v_norm_set)\n",
    "            mode = \"BLACKLIST\" if mode_req != \"auto\" else \"BLACKLIST (auto)\"\n",
    "\n",
    "    keep_canon = {v_norm2canon[n] for n in keep_norm}\n",
    "    kept_variants = {v: variants[v] for v in variants if v in keep_canon}\n",
    "    forced_exact: Dict[str, int] = {}\n",
    "    for n, yr in start_map_all_norm.items():\n",
    "        if n in keep_norm:\n",
    "            forced_exact[v_norm2canon[n]] = int(yr)\n",
    "\n",
    "    if VERBOSE >= 1:\n",
    "        print(\n",
    "            f\" [rules] Mode={mode}; kept={len(kept_variants)}/{len(variants)}; \"\n",
    "            f\"forced={len(forced_exact)}\"\n",
    "        )\n",
    "\n",
    "    return kept_variants, forced_exact, use_whitelist\n",
    "\n",
    "def allowed_starts_fine(\n",
    "    variants: Dict[str, dict],\n",
    "    forced_exact: Dict[str, int],\n",
    "    min_starts: Dict[str, int],\n",
    "    Tfine: int,\n",
    ") -> Dict[str, List[int]]:\n",
    "    ny = Tfine\n",
    "    allowed: Dict[str, List[int]] = {}\n",
    "    for v, meta in variants.items():\n",
    "        dur = meta[\"dur\"]\n",
    "        if v in forced_exact and forced_exact[v] is not None:\n",
    "            s = forced_exact[v] - START_FY\n",
    "            allowed[v] = [s] if (0 <= s <= ny - dur) else []\n",
    "            continue\n",
    "\n",
    "        s_ear = 0\n",
    "        s_lat = ny - dur\n",
    "\n",
    "        min_yr = min_starts.get(v)\n",
    "        if min_yr is not None:\n",
    "            s_min_constraint = min_yr - START_FY\n",
    "            s_ear = max(s_ear, s_min_constraint)\n",
    "\n",
    "        allowed[v] = list(range(s_ear, s_lat + 1)) if s_lat >= s_ear else []\n",
    "    return allowed\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# PV Coeff maps\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def coeff_map_for_dim_fine(\n",
    "    variants: Dict[str, dict],\n",
    "    kernels_for_dim: Dict[str, List[float]],\n",
    "    allowed: Dict[str, List[int]],\n",
    "    Tfine: int,\n",
    "    disc_vec: np.ndarray,\n",
    ") -> Dict[Tuple[str, int], float]:\n",
    "    out: Dict[Tuple[str, int], float] = {}\n",
    "    for v in variants.keys():\n",
    "        dur = variants[v][\"dur\"]\n",
    "        ker = kernels_for_dim.get(v, [])\n",
    "        if not ker:\n",
    "            continue\n",
    "        for s in allowed.get(v, []):\n",
    "            val = 0.0\n",
    "            for k, f in enumerate(ker):\n",
    "                if f == 0.0:\n",
    "                    continue\n",
    "                t = s + k\n",
    "                if 0 <= t < Tfine:\n",
    "                    val += float(f) / float(disc_vec[t])\n",
    "            if val != 0.0:\n",
    "                out[(v, s)] = val\n",
    "    return out\n",
    "\n",
    "def coeff_int(\n",
    "    coeff_map: Dict[Tuple[str, int], float],\n",
    "    scale: float = PV_SCALE,\n",
    ") -> Dict[Tuple[str, int], int]:\n",
    "    return {k: int(round(v * scale)) for k, v in coeff_map.items() if v != 0.0}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Greedy warm start\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def greedy_warm_start(\n",
    "    variants: Dict[str, dict],\n",
    "    allowed: Dict[str, List[int]],\n",
    "    Tfine: int,\n",
    "    funding_target_M: np.ndarray,  # capacity per year (not compulsory spend)\n",
    "    max_starts_per_year: int,\n",
    "    forced_exact: Dict[str, int],\n",
    "    coeff_total_map: Dict[Tuple[str, int], float],\n",
    "    reuse_sel: Optional[Dict[Tuple[str, int], int]] = None,\n",
    ") -> Dict[Tuple[str, int], int]:\n",
    "    ny = Tfine\n",
    "    capacity_prefix = np.cumsum(funding_target_M)\n",
    "    spend_cum = np.zeros(ny, dtype=float)\n",
    "    starts_count = np.zeros(ny, dtype=int)\n",
    "    sel: Dict[Tuple[str, int], int] = {}\n",
    "\n",
    "    # Try to reuse previous selection if it fits the new rules/capacity\n",
    "    if reuse_sel:\n",
    "        ok = True\n",
    "        tmp_sel: Dict[Tuple[str, int], int] = {}\n",
    "        tmp_count = starts_count.copy()\n",
    "        tmp_cum = spend_cum.copy()\n",
    "        for (v, s), on in sorted(\n",
    "            reuse_sel.items(), key=lambda kv: (kv[0][1], kv[0][0])\n",
    "        ):\n",
    "            if not on:\n",
    "                continue\n",
    "            if s not in set(allowed.get(v, [])):\n",
    "                ok = False\n",
    "                break\n",
    "            if v not in variants:\n",
    "                ok = False\n",
    "                break\n",
    "            if tmp_count[s] >= max_starts_per_year:\n",
    "                ok = False\n",
    "                break\n",
    "            d = variants[v][\"dur\"]\n",
    "            vec = np.array(variants[v][\"spend\"], dtype=float)\n",
    "            inc = np.zeros(ny, dtype=float)\n",
    "            inc[s : s + d] = vec\n",
    "            if np.any(tmp_cum + np.cumsum(inc) - capacity_prefix > 1e-9):\n",
    "                ok = False\n",
    "                break\n",
    "            tmp_cum += np.cumsum(inc)\n",
    "            tmp_count[s] += 1\n",
    "            tmp_sel[(v, s)] = 1\n",
    "        if ok:\n",
    "            sel = tmp_sel\n",
    "            starts_count = tmp_count\n",
    "            spend_cum = tmp_cum\n",
    "\n",
    "    # Enforce forced projects in chronological order\n",
    "    forced_order: List[Tuple[int, str]] = []\n",
    "    for v, yr in (forced_exact or {}).items():\n",
    "        if yr is None or v not in variants:\n",
    "            continue\n",
    "        s = int(yr - START_FY)\n",
    "        d = variants[v][\"dur\"]\n",
    "        if s < 0 or s > ny - d:\n",
    "            continue\n",
    "        if s not in set(allowed.get(v, [])):\n",
    "            continue\n",
    "        if (v, s) not in sel:\n",
    "            forced_order.append((s, v))\n",
    "    forced_order.sort()\n",
    "\n",
    "    for s, v in forced_order:\n",
    "        if starts_count[s] >= max_starts_per_year:\n",
    "            continue\n",
    "        d = variants[v][\"dur\"]\n",
    "        vec = np.array(variants[v][\"spend\"], dtype=float)\n",
    "        inc = np.zeros(ny, dtype=float)\n",
    "        inc[s : s + d] = vec\n",
    "        if np.any(spend_cum + np.cumsum(inc) - capacity_prefix > 1e-9):\n",
    "            continue\n",
    "        spend_cum += np.cumsum(inc)\n",
    "        starts_count[s] += 1\n",
    "        sel[(v, s)] = 1\n",
    "\n",
    "    remain = [v for v in variants.keys() if v not in [vv for (vv, _) in sel]]\n",
    "    order: List[Tuple[float, str]] = []\n",
    "    for v in remain:\n",
    "        denom = float(sum(variants[v][\"spend\"])) or 1e-9\n",
    "        bestpv = max(\n",
    "            (coeff_total_map.get((v, s), 0.0) for s in allowed.get(v, [])),\n",
    "            default=0.0,\n",
    "        )\n",
    "        order.append((bestpv / denom, v))\n",
    "    order.sort(reverse=True)\n",
    "\n",
    "    for _, v in order:\n",
    "        d = variants[v][\"dur\"]\n",
    "        vec = np.array(variants[v][\"spend\"], dtype=float)\n",
    "        pv_starts: List[Tuple[float, int]] = []\n",
    "        for s in allowed.get(v, []):\n",
    "            pv_starts.append((coeff_total_map.get((v, s), 0.0), s))\n",
    "        pv_starts.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        for pv, s in pv_starts:\n",
    "            if starts_count[s] >= max_starts_per_year:\n",
    "                continue\n",
    "            inc = np.zeros(ny, dtype=float)\n",
    "            inc[s : s + d] = vec\n",
    "            if np.any(spend_cum + np.cumsum(inc) - capacity_prefix > 1e-9):\n",
    "                continue\n",
    "            spend_cum += np.cumsum(inc)\n",
    "            starts_count[s] += 1\n",
    "            sel[(v, s)] = 1\n",
    "            break\n",
    "\n",
    "    return sel\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# MODEL\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "class CoptSpendMatchMO:\n",
    "    \"\"\"\n",
    "    Spend / funding model with:\n",
    "      - funding[t] FIXED to envelope[t] if active.\n",
    "      - PIECEWISE SOFT CAP on net[t] (tiers of penalties).\n",
    "      - objective = minimize backlog + penalties - PV reward\n",
    "      - MUST PURCHASE EVERY PROJECT (Hard start constraint = 1.0)\n",
    "      - DIVIDEND[t]: Restricted to end-of-life (y[t+1]=0).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        variants: Dict[str, dict],\n",
    "        allowed: Dict[str, List[int]],\n",
    "        funding_target_S: np.ndarray,  # scaled per-year capacity\n",
    "        Tn: int,\n",
    "        taper_start_idx: int,  # legacy; not used by new logic\n",
    "        spend_by_year: Dict[str, List[float]],\n",
    "        max_starts_per_year: int,\n",
    "        is_whitelist_model: bool,\n",
    "        env: Optional[co.Envr] = None,\n",
    "        name: str = \"spend_match_mo\",\n",
    "        *,\n",
    "        relax_binaries: bool = False,\n",
    "    ):\n",
    "        self.Tn = int(Tn)\n",
    "        self.taper_start_idx = taper_start_idx\n",
    "\n",
    "        self.env = env or co.Envr()\n",
    "        self.m: co.Model = self.env.createModel(name)\n",
    "        init_params = {\n",
    "            \"RandSeed\": int(SOLVER_SEED_DEFAULT),\n",
    "            \"Threads\": int(SOLVER_THREADS_DEFAULT),\n",
    "            \"MipStartMode\": 2,\n",
    "            \"Logging\": 1,\n",
    "            \"Display\": 1,\n",
    "            \"Presolve\": 1,\n",
    "            \"Scaling\": 1,\n",
    "        }\n",
    "        _apply_params_logged(self.m, init_params, header=\"Model init params\")\n",
    "\n",
    "        # Funding capacity (scaled) per year – envelope path\n",
    "        self.funding_target_S = funding_target_S\n",
    "\n",
    "        # Decision x[v,s]\n",
    "        self.x: Dict[Tuple[str, int], co.Var] = {}\n",
    "        self.by_year: Dict[int, List[Tuple[str, int]]] = defaultdict(list)\n",
    "        x_vtype = COPT.CONTINUOUS if relax_binaries else COPT.BINARY\n",
    "        for v in variants.keys():\n",
    "            for s in allowed.get(v, []):\n",
    "                var = self.m.addVar(lb=0.0, ub=1.0, vtype=x_vtype, name=f\"x[{v}|{s}]\")\n",
    "                self.x[(v, s)] = var\n",
    "                if 0 <= s < self.Tn:\n",
    "                    self.by_year[s].append((v, s))\n",
    "\n",
    "        # Envelope-active indicator y[t]; monotone non-increasing.\n",
    "        y_vtype = COPT.CONTINUOUS if relax_binaries else COPT.BINARY\n",
    "        self.y: List[co.Var] = [\n",
    "            self.m.addVar(lb=0.0, ub=1.0, vtype=y_vtype, name=f\"active[{t}]\")\n",
    "            for t in range(self.Tn)\n",
    "        ]\n",
    "        for t in range(self.Tn - 1):\n",
    "            self.m.addConstr(self.y[t] >= self.y[t + 1], name=f\"active_noninc[{t}]\")\n",
    "\n",
    "        # Spend convolution (scaled)\n",
    "        spend_terms: List[List[Tuple[co.Var, int]]] = [[] for _ in range(self.Tn)]\n",
    "        for (v, s), var in self.x.items():\n",
    "            vec = spend_by_year[v]\n",
    "            for k, amtM in enumerate(vec):\n",
    "                if amtM == 0.0:\n",
    "                    continue\n",
    "                t = s + k\n",
    "                if 0 <= t < self.Tn:\n",
    "                    spend_terms[t].append((var, iround(amtM, SPEND_SCALE)))\n",
    "\n",
    "        self.spend_expr: List[co.LinExpr] = []\n",
    "        for t in range(self.Tn):\n",
    "            if spend_terms[t]:\n",
    "                self.spend_expr.append(\n",
    "                    co.quicksum(coeff * var for (var, coeff) in spend_terms[t])\n",
    "                )\n",
    "            else:\n",
    "                self.spend_expr.append(co.LinExpr(0.0))\n",
    "\n",
    "        # If there is spend in year t from some x[v,s], then y[t] must be 1.\n",
    "        for t in range(self.Tn):\n",
    "            for (var, _coeff) in spend_terms[t]:\n",
    "                self.m.addConstr(self.y[t] >= var)\n",
    "\n",
    "        # Funding actually drawn each year (scaled units).\n",
    "        # FIXED: Must equal the envelope if y[t] is 1.\n",
    "        self.funding: List[co.Var] = []\n",
    "        for t in range(self.Tn):\n",
    "            ub = float(self.funding_target_S[t])\n",
    "            var = self.m.addVar(lb=0.0, ub=ub, vtype=COPT.CONTINUOUS, name=f\"fund[{t}]\")\n",
    "            self.funding.append(var)\n",
    "            # funding[t] == y[t] * envelope_t\n",
    "            self.m.addConstr(var == self.y[t] * ub, name=f\"fund_fixed[{t}]\")\n",
    "\n",
    "        # -- DIVIDEND VARIABLE (Restricted to End-of-Life) --\n",
    "        self.dividend: List[co.Var] = [\n",
    "            self.m.addVar(lb=0.0, vtype=COPT.CONTINUOUS, name=f\"dividend[{t}]\")\n",
    "            for t in range(self.Tn)\n",
    "        ]\n",
    "        net_bigM = float(np.sum(self.funding_target_S))\n",
    "\n",
    "        # NEW CONSTRAINT: RESTRICT DIVIDEND\n",
    "        # If y[t+1] == 1, then dividend[t] must be 0.\n",
    "        for t in range(self.Tn - 1):\n",
    "            self.m.addConstr(\n",
    "                self.dividend[t] <= net_bigM * (1.0 - self.y[t + 1]),\n",
    "                name=f\"div_restrict[{t}]\",\n",
    "            )\n",
    "        # Last year (Tn-1) is always allowed to dividend (y[Tn] is implicitly 0).\n",
    "\n",
    "        # Net path (non-negative; no debt).\n",
    "        self.net: List[co.Var] = [\n",
    "            self.m.addVar(lb=0.0, vtype=COPT.CONTINUOUS, name=f\"net[{t}]\")\n",
    "            for t in range(self.Tn)\n",
    "        ]\n",
    "\n",
    "        # Year 0: Net[0] = Fund[0] - Spend[0] - Dividend[0]\n",
    "        self.m.addConstr(\n",
    "            self.net[0] == self.funding[0] - self.spend_expr[0] - self.dividend[0],\n",
    "            name=\"net0\",\n",
    "        )\n",
    "        # Subsequent: Net[t] = Net[t-1] + Fund[t] - Spend[t] - Dividend[t]\n",
    "        for t in range(1, self.Tn):\n",
    "            self.m.addConstr(\n",
    "                self.net[t]\n",
    "                == self.net[t - 1]\n",
    "                + self.funding[t]\n",
    "                - self.spend_expr[t]\n",
    "                - self.dividend[t],\n",
    "                name=f\"net[{t}]\",\n",
    "            )\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # PIECEWISE LINEAR SOFT CAP\n",
    "        # ------------------------------------------------------------------\n",
    "        self.excess_tiers: List[List[co.Var]] = [[] for _ in range(self.Tn)]\n",
    "        self.tier_penalties_expr = co.LinExpr(0.0)\n",
    "\n",
    "        base_threshold = PIECEWISE_CAP_TIERS[0][0]\n",
    "\n",
    "        for t in range(self.Tn):\n",
    "            env_S = float(self.funding_target_S[t])\n",
    "            base_cap_S = env_S * base_threshold\n",
    "\n",
    "            tier_vars_t: List[co.Var] = []\n",
    "            for i, (thresh_start, weight) in enumerate(PIECEWISE_CAP_TIERS):\n",
    "                is_last = i == len(PIECEWISE_CAP_TIERS) - 1\n",
    "                if not is_last:\n",
    "                    thresh_next = PIECEWISE_CAP_TIERS[i + 1][0]\n",
    "                    width_S = env_S * (thresh_next - thresh_start)\n",
    "                    v_tier = self.m.addVar(\n",
    "                        lb=0.0,\n",
    "                        ub=width_S,\n",
    "                        vtype=COPT.CONTINUOUS,\n",
    "                        name=f\"exc_t{i}_{t}\",\n",
    "                    )\n",
    "                else:\n",
    "                    v_tier = self.m.addVar(\n",
    "                        lb=0.0, vtype=COPT.CONTINUOUS, name=f\"exc_t{i}_{t}\"\n",
    "                    )\n",
    "\n",
    "                tier_vars_t.append(v_tier)\n",
    "                self.tier_penalties_expr.addTerm(v_tier, weight)\n",
    "\n",
    "            self.excess_tiers[t] = tier_vars_t\n",
    "\n",
    "            if t < self.Tn - 1:\n",
    "                sum_excess_t = co.quicksum(tier_vars_t)\n",
    "                self.m.addConstr(\n",
    "                    self.net[t]\n",
    "                    <= base_cap_S\n",
    "                    + sum_excess_t\n",
    "                    + net_bigM * (1.0 - self.y[t + 1]),\n",
    "                    name=f\"net_cap_piecewise[{t}]\",\n",
    "                )\n",
    "            else:\n",
    "                # Last year cleanup – no excess tiers; just cap by net_bigM.\n",
    "                for v in tier_vars_t:\n",
    "                    self.m.addConstr(v == 0.0)\n",
    "                self.m.addConstr(self.net[t] <= net_bigM, name=f\"net_cap_last[{t}]\")\n",
    "\n",
    "        # Auxiliary backlog variables\n",
    "        self.backlog: List[co.Var] = [\n",
    "            self.m.addVar(lb=0.0, vtype=COPT.CONTINUOUS, name=f\"backlog[{t}]\")\n",
    "            for t in range(self.Tn)\n",
    "        ]\n",
    "        for t in range(self.Tn):\n",
    "            if t < self.Tn - 1:\n",
    "                self.m.addConstr(\n",
    "                    self.backlog[t]\n",
    "                    >= self.net[t] - net_bigM * (1.0 - self.y[t + 1]),\n",
    "                    name=f\"backlog_lb_link[{t}]\",\n",
    "                )\n",
    "                self.m.addConstr(\n",
    "                    self.backlog[t]\n",
    "                    <= self.net[t] + net_bigM * (1.0 - self.y[t + 1]),\n",
    "                    name=f\"backlog_ub_link[{t}]\",\n",
    "                )\n",
    "            else:\n",
    "                self.m.addConstr(\n",
    "                    self.backlog[t] == 0.0,\n",
    "                    name=\"backlog_last_zero\",\n",
    "                )\n",
    "\n",
    "        # Annual backlog sum\n",
    "        self.annual_backlog_sum = co.quicksum(self.backlog[t] for t in range(self.Tn))\n",
    "\n",
    "        # Starts: per-project caps; per-year caps\n",
    "        start_constr = (COPT.EQUAL, 1.0)\n",
    "\n",
    "        if not relax_binaries:\n",
    "            for v in {vv for vv, _ in self.x}:\n",
    "                cols = [self.x[(vv, s)] for (vv, s) in self.x if vv == v]\n",
    "                if cols:\n",
    "                    self.m.addConstr(\n",
    "                        co.quicksum(cols),\n",
    "                        start_constr[0],\n",
    "                        start_constr[1],\n",
    "                        name=f\"start_once[{v}]\",\n",
    "                    )\n",
    "            for t in range(self.Tn):\n",
    "                cols = [self.x[(v, s)] for (v, s) in self.by_year.get(t, [])]\n",
    "                if cols:\n",
    "                    self.m.addConstr(\n",
    "                        co.quicksum(cols) <= int(max_starts_per_year),\n",
    "                        name=f\"cap_starts[{t}]\",\n",
    "                    )\n",
    "        else:\n",
    "            for v in {vv for vv, _ in self.x}:\n",
    "                cols = [self.x[(vv, s)] for (vv, s) in self.x if vv == v]\n",
    "                if cols:\n",
    "                    self.m.addConstr(\n",
    "                        co.quicksum(cols),\n",
    "                        start_constr[0],\n",
    "                        start_constr[1],\n",
    "                        name=f\"start_once_relax[{v}]\",\n",
    "                    )\n",
    "            for t in range(self.Tn):\n",
    "                cols = [self.x[(v, s)] for (v, s) in self.by_year.get(t, [])]\n",
    "                if cols:\n",
    "                    self.m.addConstr(\n",
    "                        co.quicksum(cols) <= float(max_starts_per_year),\n",
    "                        name=f\"cap_starts_relax[{t}]\",\n",
    "                    )\n",
    "\n",
    "        if self.x:\n",
    "            self.m.addConstr(\n",
    "                co.quicksum(self.x.values()) >= 1.0,\n",
    "                name=\"at_least_one_project\",\n",
    "            )\n",
    "\n",
    "        self._obj_cache: Dict[str, co.LinExpr] = {}\n",
    "\n",
    "    # ---- Wrappers -----------------------------------------------------------\n",
    "    def obj_expr(\n",
    "        self,\n",
    "        coeff_int_map: Dict[Tuple[str, int], int],\n",
    "        cache_key: Optional[str] = None,\n",
    "    ) -> co.LinExpr:\n",
    "        if cache_key and cache_key in self._obj_cache:\n",
    "            return self._obj_cache[cache_key]\n",
    "        terms = []\n",
    "        for (v, s), w in coeff_int_map.items():\n",
    "            var = self.x.get((v, s))\n",
    "            if var is not None and int(w) != 0:\n",
    "                terms.append(w * var)\n",
    "        expr = co.quicksum(terms) if terms else co.LinExpr(0.0)\n",
    "        if cache_key:\n",
    "            self._obj_cache[cache_key] = expr\n",
    "        return expr\n",
    "\n",
    "    def add_floor(self, expr: co.LinExpr, target_unscaled: float, name: str) -> None:\n",
    "        self.m.addConstr(\n",
    "            expr >= int(math.floor(target_unscaled * PV_SCALE)),\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "    def add_hint_from_starts(self, sel: Dict[Tuple[str, int], int]) -> None:\n",
    "        if not sel:\n",
    "            return\n",
    "        try:\n",
    "            vars_: List[co.Var] = []\n",
    "            vals_: List[float] = []\n",
    "            for (k, on) in sel.items():\n",
    "                if on and k in self.x:\n",
    "                    vars_.append(self.x[k])\n",
    "                    vals_.append(1.0)\n",
    "            if vars_:\n",
    "                self.m.addMIPStart(vars_, vals_)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Solve helpers\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "@dataclass\n",
    "class SolveResult:\n",
    "    status: int\n",
    "    has_inc: bool\n",
    "    gap: Optional[float]\n",
    "    seconds: float\n",
    "    victory_lap_triggered: bool = False\n",
    "\n",
    "class Phase2Callback(co.CallbackBase):\n",
    "    \"\"\"\n",
    "    Dynamic Victory Lap callback:\n",
    "      - Monitors BestObj / BestBnd via getInfo(COPT.CbInfo.*).\n",
    "      - If gap < target_gap: start a countdown (victory_lap_duration).\n",
    "      - Otherwise: interrupts after normal_time_limit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        normal_time_limit: float,\n",
    "        target_gap: float,\n",
    "        victory_lap_duration: float = 60.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.normal_time_limit = float(normal_time_limit)\n",
    "        self.target_gap = float(target_gap)\n",
    "        self.victory_lap_duration = float(victory_lap_duration)\n",
    "        self.start_time = time.time()\n",
    "        self.victory_start_time: Optional[float] = None\n",
    "        self.triggered_victory: bool = False\n",
    "\n",
    "    def callback(self) -> None:\n",
    "        # Only respond in MIP solution / node contexts (if we could detect them)\n",
    "        where = self.getWhere()\n",
    "        valid_contexts: List[int] = []\n",
    "        if CTX_MIPSOL:\n",
    "            valid_contexts.append(CTX_MIPSOL)\n",
    "        if CTX_MIPNODE:\n",
    "            valid_contexts.append(CTX_MIPNODE)\n",
    "        if valid_contexts and where not in valid_contexts:\n",
    "            return\n",
    "\n",
    "        now = time.time()\n",
    "        elapsed = now - self.start_time\n",
    "\n",
    "        # If we already triggered the Victory Lap, just watch the timer.\n",
    "        if self.triggered_victory:\n",
    "            if (\n",
    "                self.victory_start_time is not None\n",
    "                and now - self.victory_start_time >= self.victory_lap_duration\n",
    "            ):\n",
    "                self.interrupt()\n",
    "            return\n",
    "\n",
    "        # Pull BestObj / BestBnd from COPT\n",
    "        try:\n",
    "            best_obj = float(self.getInfo(COPT.CbInfo.BestObj))\n",
    "            best_bnd = float(self.getInfo(COPT.CbInfo.BestBnd))\n",
    "        except Exception:\n",
    "            return\n",
    "\n",
    "        # Check if we actually have an incumbent yet.\n",
    "        if not math.isfinite(best_obj):\n",
    "            return\n",
    "        try:\n",
    "            if abs(best_obj) >= 0.5 * float(COPT.INFINITY):\n",
    "                return\n",
    "        except Exception:\n",
    "            # If INFINITY is not available or weird, fall back to just finite check.\n",
    "            pass\n",
    "\n",
    "        denom = max(1.0, abs(best_obj))\n",
    "        current_gap = abs(best_bnd - best_obj) / denom\n",
    "\n",
    "        # Victory trigger\n",
    "        if current_gap <= self.target_gap:\n",
    "            self.triggered_victory = True\n",
    "            self.victory_start_time = now\n",
    "            return\n",
    "\n",
    "        # Normal time cutoff (only if we haven't triggered victory)\n",
    "        if elapsed >= self.normal_time_limit:\n",
    "            self.interrupt()\n",
    "\n",
    "# --- Profile-specific solve strategies --------------------------------------\n",
    "def _solve_single_phase(\n",
    "    m: co.Model, stage: str, base_time: float, rel_gap: float\n",
    ") -> SolveResult:\n",
    "    \"\"\"\n",
    "    v94.11-style single-phase solve with optional precision top-up.\n",
    "    Used for 'fast' and 'balanced' profiles.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    _log(f\"[{stage}] Single-phase solve: {base_time:.0f}s, target gap={rel_gap:.4f}\")\n",
    "    _apply_params_logged(\n",
    "        m,\n",
    "        {\"RelGap\": float(rel_gap), \"TimeLimit\": float(base_time)},\n",
    "        header=f\"{stage} main settings\",\n",
    "    )\n",
    "    m.solve()\n",
    "\n",
    "    has_inc = _has_incumbent(m)\n",
    "    gap = _best_gap(m)\n",
    "\n",
    "    # Optional precision top-up if we have an incumbent but the gap is still loose.\n",
    "    if has_inc and (gap is None or gap > PRECISION_TOPUP_GAP):\n",
    "        elapsed = time.time() - t0\n",
    "        remaining_time = max(0.0, base_time - elapsed)\n",
    "        top_up_time = max(remaining_time, PRECISION_TOPUP_TIME)\n",
    "        if top_up_time > 5.0:\n",
    "            _log(\n",
    "                f\"[{stage}] Precision top-up: +{top_up_time:.0f}s, \"\n",
    "                f\"target gap={PRECISION_TOPUP_GAP:.4f}\"\n",
    "            )\n",
    "            _apply_params_logged(\n",
    "                m,\n",
    "                {\n",
    "                    \"TimeLimit\": float(top_up_time),\n",
    "                    \"RelGap\": float(PRECISION_TOPUP_GAP),\n",
    "                },\n",
    "                header=f\"{stage} top-up settings\",\n",
    "            )\n",
    "            m.solve()\n",
    "            has_inc = _has_incumbent(m)\n",
    "            gap = _best_gap(m)\n",
    "\n",
    "    final_status = int(m.status)\n",
    "    seconds = time.time() - t0\n",
    "    if final_status == COPT.INFEASIBLE:\n",
    "        _log(f\"[{stage}] Solve status: INFEASIBLE.\")\n",
    "        return SolveResult(\n",
    "            status=final_status, has_inc=False, gap=None, seconds=seconds\n",
    "        )\n",
    "\n",
    "    return SolveResult(\n",
    "        status=final_status, has_inc=has_inc, gap=gap, seconds=seconds\n",
    "    )\n",
    "\n",
    "def _solve_two_phase(\n",
    "    m: co.Model, stage: str, base_time: float, rel_gap: float\n",
    ") -> SolveResult:\n",
    "    \"\"\"\n",
    "    2-Phase: Probe + Verify+VictoryLap (for 'thorough' profile).\n",
    "    \"\"\"\n",
    "    t_start = time.time()\n",
    "    t_probe = max(5.0, base_time * 0.10)\n",
    "    t_verify = max(10.0, base_time - t_probe)\n",
    "\n",
    "    # Phase 1: Probe\n",
    "    _log(f\"[{stage}] === Phase 1/2: Probe ({t_probe:.0f}s) ===\")\n",
    "    _apply_params_logged(\n",
    "        m,\n",
    "        {\n",
    "            \"TimeLimit\": float(t_probe),\n",
    "            \"RelGap\": float(rel_gap),\n",
    "        },\n",
    "        header=f\"{stage} Probe Params\",\n",
    "    )\n",
    "    m.solve()\n",
    "\n",
    "    # Early exit if we already reached the target gap.\n",
    "    if _has_incumbent(m):\n",
    "        g = _best_gap(m)\n",
    "        if g is not None and g <= rel_gap:\n",
    "            seconds = time.time() - t_start\n",
    "            _log(\n",
    "                f\"[{stage}] Probe hit target gap {g:.4%} ≤ {rel_gap:.4%}, \"\n",
    "                \"skipping Verify.\"\n",
    "            )\n",
    "            return SolveResult(\n",
    "                status=int(m.status),\n",
    "                has_inc=True,\n",
    "                gap=g,\n",
    "                seconds=seconds,\n",
    "            )\n",
    "\n",
    "    # Phase 2: Verify + Victory Lap\n",
    "    _log(\n",
    "        f\"[{stage}] === Phase 2/2: Verify ({t_verify:.0f}s) + Dynamic Victory Lap ===\"\n",
    "    )\n",
    "    _apply_params_logged(\n",
    "        m,\n",
    "        {\n",
    "            \"TimeLimit\": float(COPT.INFINITY),\n",
    "            \"RelGap\": 0.0,  # let callback drive termination\n",
    "        },\n",
    "        header=f\"{stage} Verify Params\",\n",
    "    )\n",
    "\n",
    "    cb = Phase2Callback(normal_time_limit=t_verify, target_gap=rel_gap)\n",
    "\n",
    "    # Attach callback; if unsupported, fall back to single-phase behaviour.\n",
    "    try:\n",
    "        context_mask = 0\n",
    "        if CTX_MIPSOL:\n",
    "            context_mask |= CTX_MIPSOL\n",
    "        if CTX_MIPNODE:\n",
    "            context_mask |= CTX_MIPNODE\n",
    "        if context_mask:\n",
    "            m.setCallback(cb, context_mask)\n",
    "        else:\n",
    "            m.setCallback(cb)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            m.setCallback(cb)\n",
    "        except Exception:\n",
    "            _log(\n",
    "                f\"[{stage}] Callback not supported; falling back to \"\n",
    "                \"single-phase solver.\"\n",
    "            )\n",
    "            return _solve_single_phase(m, stage, base_time, rel_gap)\n",
    "\n",
    "    m.solve()\n",
    "    # Try to clear the callback (API differences tolerated).\n",
    "    try:\n",
    "        m.setCallback(None, 0)\n",
    "    except Exception:\n",
    "        try:\n",
    "            m.setCallback(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    final_status = int(m.status)\n",
    "    seconds = time.time() - t_start\n",
    "    if final_status == COPT.INFEASIBLE:\n",
    "        _log(f\"[{stage}] Solve status: INFEASIBLE.\")\n",
    "        return SolveResult(\n",
    "            status=final_status,\n",
    "            has_inc=False,\n",
    "            gap=None,\n",
    "            seconds=seconds,\n",
    "            victory_lap_triggered=cb.triggered_victory,\n",
    "        )\n",
    "\n",
    "    gap = _best_gap(m)\n",
    "    if cb.triggered_victory:\n",
    "        _log(\n",
    "            f\"[{stage}] Victory Lap triggered; final gap: \"\n",
    "            f\"{gap if gap is not None else float('nan'):.4%}\"\n",
    "        )\n",
    "\n",
    "    return SolveResult(\n",
    "        status=final_status,\n",
    "        has_inc=_has_incumbent(m),\n",
    "        gap=gap,\n",
    "        seconds=seconds,\n",
    "        victory_lap_triggered=cb.triggered_victory,\n",
    "    )\n",
    "\n",
    "def _solve_three_phase(\n",
    "    m: co.Model, stage: str, base_time: float, rel_gap: float\n",
    ") -> SolveResult:\n",
    "    \"\"\"\n",
    "    3-Phase: Probe + Verify+VictoryLap + Grind (for 'ultra' profile).\n",
    "    \"\"\"\n",
    "    t_start = time.time()\n",
    "\n",
    "    # Time splits\n",
    "    t_probe = max(5.0, base_time * 0.10)\n",
    "    t_verify = max(10.0, base_time * 0.30)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Phase 1: Probe\n",
    "    # -------------------------------------------------------------------------\n",
    "    _log(f\"[{stage}] === Phase 1/3: Probe ({t_probe:.0f}s) ===\")\n",
    "    _apply_params_logged(\n",
    "        m,\n",
    "        {\n",
    "            \"TimeLimit\": float(t_probe),\n",
    "            \"RelGap\": float(rel_gap),\n",
    "        },\n",
    "        header=f\"{stage} Probe Params\",\n",
    "    )\n",
    "    m.solve()\n",
    "\n",
    "    if _has_incumbent(m):\n",
    "        g = _best_gap(m)\n",
    "        if g is not None and g <= rel_gap:\n",
    "            seconds = time.time() - t_start\n",
    "            _log(\n",
    "                f\"[{stage}] Probe hit target gap {g:.4%} ≤ {rel_gap:.4%}, \"\n",
    "                \"skipping Verify & Grind.\"\n",
    "            )\n",
    "            return SolveResult(\n",
    "                status=int(m.status),\n",
    "                has_inc=True,\n",
    "                gap=g,\n",
    "                seconds=seconds,\n",
    "            )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Phase 2: Verify (with Victory Lap)\n",
    "    # -------------------------------------------------------------------------\n",
    "    _log(\n",
    "        f\"[{stage}] === Phase 2/3: Verify ({t_verify:.0f}s) + Dynamic Victory Lap ===\"\n",
    "    )\n",
    "    _apply_params_logged(\n",
    "        m,\n",
    "        {\n",
    "            \"TimeLimit\": float(COPT.INFINITY),\n",
    "            \"RelGap\": 0.0,\n",
    "        },\n",
    "        header=f\"{stage} Verify Params\",\n",
    "    )\n",
    "\n",
    "    cb = Phase2Callback(normal_time_limit=t_verify, target_gap=rel_gap)\n",
    "\n",
    "    try:\n",
    "        context_mask = 0\n",
    "        if CTX_MIPSOL:\n",
    "            context_mask |= CTX_MIPSOL\n",
    "        if CTX_MIPNODE:\n",
    "            context_mask |= CTX_MIPNODE\n",
    "        if context_mask:\n",
    "            m.setCallback(cb, context_mask)\n",
    "        else:\n",
    "            m.setCallback(cb)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            m.setCallback(cb)\n",
    "        except Exception:\n",
    "            _log(\n",
    "                f\"[{stage}] Callback not supported; falling back to single-phase \"\n",
    "                \"solver.\"\n",
    "            )\n",
    "            return _solve_single_phase(m, stage, base_time, rel_gap)\n",
    "\n",
    "    m.solve()\n",
    "    try:\n",
    "        m.setCallback(None, 0)\n",
    "    except Exception:\n",
    "        try:\n",
    "            m.setCallback(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    current_gap = _best_gap(m)\n",
    "    if cb.triggered_victory:\n",
    "        seconds = time.time() - t_start\n",
    "        _log(\n",
    "            f\"[{stage}] Victory Lap triggered & completed. Gap: \"\n",
    "            f\"{current_gap if current_gap is not None else float('nan'):.4%} \"\n",
    "            f\"< {rel_gap:.4%}. Skipping Grind.\"\n",
    "        )\n",
    "        return SolveResult(\n",
    "            status=int(m.status),\n",
    "            has_inc=_has_incumbent(m),\n",
    "            gap=current_gap,\n",
    "            seconds=seconds,\n",
    "            victory_lap_triggered=True,\n",
    "        )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Phase 3: Grind (remaining budget)\n",
    "    # -------------------------------------------------------------------------\n",
    "    elapsed = time.time() - t_start\n",
    "    remaining = max(10.0, base_time - elapsed)\n",
    "\n",
    "    _log(f\"[{stage}] === Phase 3/3: Grind ({remaining:.0f}s) ===\")\n",
    "    _apply_params_logged(\n",
    "        m,\n",
    "        {\n",
    "            \"TimeLimit\": float(remaining),\n",
    "            \"RelGap\": float(rel_gap),\n",
    "        },\n",
    "        header=f\"{stage} Grind Params\",\n",
    "    )\n",
    "    m.solve()\n",
    "\n",
    "    final_status = int(m.status)\n",
    "    seconds = time.time() - t_start\n",
    "    if final_status == COPT.INFEASIBLE:\n",
    "        _log(f\"[{stage}] Solve status: INFEASIBLE.\")\n",
    "        return SolveResult(\n",
    "            status=final_status, has_inc=False, gap=None, seconds=seconds\n",
    "        )\n",
    "\n",
    "    return SolveResult(\n",
    "        status=final_status,\n",
    "        has_inc=_has_incumbent(m),\n",
    "        gap=_best_gap(m),\n",
    "        seconds=seconds,\n",
    "        victory_lap_triggered=False,\n",
    "    )\n",
    "\n",
    "def solve_model(\n",
    "    m: co.Model,\n",
    "    stage: str,\n",
    "    base_time: float,\n",
    "    rel_gap: float,\n",
    ") -> SolveResult:\n",
    "    \"\"\"\n",
    "    Profile-aware wrapper:\n",
    "\n",
    "      - 'fast', 'balanced'  → single-phase (v94.11-style)\n",
    "      - 'thorough'          → 2-phase (Probe + Verify + Victory Lap)\n",
    "      - 'ultra'             → 3-phase (Probe + Verify + Victory Lap + Grind)\n",
    "    \"\"\"\n",
    "    profile = (OPTIMISATION_PROFILE or \"thorough\").strip().lower()\n",
    "    if profile in (\"fast\", \"balanced\"):\n",
    "        return _solve_single_phase(m, stage, base_time, rel_gap)\n",
    "    elif profile == \"thorough\":\n",
    "        return _solve_two_phase(m, stage, base_time, rel_gap)\n",
    "    elif profile == \"ultra\":\n",
    "        return _solve_three_phase(m, stage, base_time, rel_gap)\n",
    "    else:\n",
    "        _log(\n",
    "            f\"[{stage}] Unknown OPTIMISATION_PROFILE={OPTIMISATION_PROFILE!r}; \"\n",
    "            \"falling back to single-phase strategy.\"\n",
    "        )\n",
    "        return _solve_single_phase(m, stage, base_time, rel_gap)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Selection / PV helpers\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def selection_from_vars(\n",
    "    xmap: Dict[Tuple[str, int], co.Var]\n",
    ") -> Dict[Tuple[str, int], int]:\n",
    "    out: Dict[Tuple[str, int], int] = {}\n",
    "    for (k, var) in xmap.items():\n",
    "        try:\n",
    "            val = float(var.X)\n",
    "        except Exception:\n",
    "            val = 0.0\n",
    "        if val > 0.5:\n",
    "            out[k] = 1\n",
    "    return out\n",
    "\n",
    "def selection_from_values(\n",
    "    xmap: Dict[Tuple[str, int], co.Var],\n",
    "    val_by_id: Optional[Dict[int, float]],\n",
    ") -> Dict[Tuple[str, int], int]:\n",
    "    out: Dict[Tuple[str, int], int] = {}\n",
    "    for key, var in xmap.items():\n",
    "        if _val(val_by_id, var) > 0.5:\n",
    "            out[key] = 1\n",
    "    return out\n",
    "\n",
    "def pv_from_selection(\n",
    "    coeff_map: Dict[Tuple[str, int], float],\n",
    "    sel: Dict[Tuple[str, int], int],\n",
    ") -> float:\n",
    "    return float(sum(coeff_map.get(k, 0.0) for k, on in sel.items() if on))\n",
    "\n",
    "def extract_solution_values(M: CoptSpendMatchMO) -> Optional[Dict[int, float]]:\n",
    "    if not _has_incumbent(M.m):\n",
    "        return None\n",
    "\n",
    "    val_by_id: Dict[int, float] = {}\n",
    "    all_vars: List[co.Var] = []\n",
    "\n",
    "    all_vars.extend(M.x.values())\n",
    "    if hasattr(M, \"net\"):\n",
    "        all_vars.extend(M.net)\n",
    "    if hasattr(M, \"funding\"):\n",
    "        all_vars.extend(M.funding)\n",
    "    if hasattr(M, \"y\"):\n",
    "        all_vars.extend(M.y)\n",
    "    if hasattr(M, \"backlog\"):\n",
    "        all_vars.extend(M.backlog)\n",
    "    if hasattr(M, \"dividend\"):\n",
    "        all_vars.extend(M.dividend)\n",
    "    if hasattr(M, \"excess_tiers\"):\n",
    "        for t in range(M.Tn):\n",
    "            all_vars.extend(M.excess_tiers[t])\n",
    "\n",
    "    for var in all_vars:\n",
    "        if var is not None:\n",
    "            val_by_id[id(var)] = _val(None, var)\n",
    "    return val_by_id\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Diagnostics / PKL\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def assert_and_log_invariants(\n",
    "    M: CoptSpendMatchMO,\n",
    "    funding_target_M: np.ndarray,\n",
    "    val_by_id: Dict[int, float],\n",
    "    *,\n",
    "    label: str,\n",
    ") -> None:\n",
    "    fy = cal_years(M.Tn)\n",
    "    net = np.array([_val(val_by_id, M.net[t]) for t in range(M.Tn)], dtype=float)\n",
    "\n",
    "    # Check no-debt rule\n",
    "    if np.any(net < -1e-5):  # Allow for small numerical noise\n",
    "        viol_t = int(np.argmin(net))\n",
    "        raise AssertionError(\n",
    "            f\"[{label}] debt detected at year {fy[viol_t]}! \"\n",
    "            f\"Net balance went negative: {net[viol_t]/SPEND_SCALE:.3f} M\"\n",
    "        )\n",
    "\n",
    "    print(f\"[diag] {label}:\")\n",
    "    print(\n",
    "        f\"[diag] head net=\"\n",
    "        f\"{[(fy[i], round(net[i]/SPEND_SCALE, 3)) for i in range(min(5, M.Tn))]} \"\n",
    "        f\"tail net=\"\n",
    "        f\"{[(fy[i], round(net[i]/SPEND_SCALE, 3)) for i in range(max(0, M.Tn-5), M.Tn)]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[diag] Closing Net Balance (raw model): {net[-1]/SPEND_SCALE:,.2f} M\"\n",
    "    )\n",
    "\n",
    "def dump_pickle_full(\n",
    "    M: CoptSpendMatchMO,\n",
    "    tag: str,\n",
    "    *,\n",
    "    projects: Dict[str, dict],\n",
    "    variants: Dict[str, dict],\n",
    "    costs_input_df: pd.DataFrame,\n",
    "    ben_kernel_df: pd.DataFrame,\n",
    "    kernels_by_dim: Dict[str, Dict[str, List[float]]],\n",
    "    benefit_rate: float,\n",
    "    scenario_name: str,\n",
    "    primary_dim: str,\n",
    "    Tfine: int,\n",
    "    funding_target_M: np.ndarray,  # envelope capacity path (M)\n",
    "    sel_override: Optional[Dict[Tuple[str, int], int]] = None,\n",
    "    val_override: Optional[Dict[int, float]] = None,\n",
    "    gap_override: Optional[float] = None,\n",
    "    extra_diag: Optional[Dict[str, str]] = None,\n",
    "    status_override: Optional[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Build all derived tables for a given model + selection and write them to a\n",
    "    pickle file. Also records the final relative gap (fraction and percent).\n",
    "    \"\"\"\n",
    "    ny = Tfine\n",
    "    fy = cal_years(ny)\n",
    "\n",
    "    # Selection\n",
    "    if sel_override is not None:\n",
    "        sel = sel_override\n",
    "    elif val_override is not None:\n",
    "        sel = selection_from_values(M.x, val_override)\n",
    "    else:\n",
    "        sel = selection_from_vars(M.x)\n",
    "\n",
    "    status_text = status_override or \"OK\"\n",
    "    if not sel:\n",
    "        fn = CACHE / f\"{(PKL_PREFIX or '')}{tag}_noSol.pkl\"\n",
    "        payload = {\n",
    "            \"status\": \"NoSolve\",\n",
    "            \"reason\": \"no selected starts\",\n",
    "            \"objective\": primary_dim,\n",
    "            \"created_at\": _now_stamp(),\n",
    "            \"gap\": None,\n",
    "            \"gap_pct\": None,\n",
    "        }\n",
    "        if extra_diag:\n",
    "            payload[\"diagnostic\"] = extra_diag\n",
    "        pkl_save(fn, payload)\n",
    "        return\n",
    "\n",
    "    # Schedule table\n",
    "    rows = []\n",
    "    for (v, s) in sorted(sel.keys()):\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Project\": v,\n",
    "                \"StartFY\": START_FY + s,\n",
    "                \"EndFY\": START_FY + s + variants[v][\"dur\"] - 1,\n",
    "                \"Dur\": variants[v][\"dur\"],\n",
    "                \"Scenario\": scenario_name,\n",
    "                \"PrimaryDim\": primary_dim,\n",
    "            }\n",
    "        )\n",
    "    df_sched = pd.DataFrame(rows).sort_values(\n",
    "        [\"StartFY\", \"Project\"], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Spend per project, per year (M)\n",
    "    df_sp = pd.DataFrame(0.0, index=list(projects.keys()), columns=fy)\n",
    "    for (v, s) in sel.keys():\n",
    "        vec = variants[v][\"spend\"]\n",
    "        for i, amt in enumerate(vec):\n",
    "            t = s + i\n",
    "            if 0 <= t < ny:\n",
    "                df_sp.loc[v, fy[t]] += float(amt)\n",
    "    df_sp.loc[\"Total Spend\"] = df_sp.sum()\n",
    "\n",
    "    # Determine last spend year (for reporting / closure)\n",
    "    total_spend_series = df_sp.loc[\"Total Spend\"]\n",
    "    last_spend_year = None\n",
    "    for yr in reversed(fy):\n",
    "        if abs(float(total_spend_series.get(yr, 0.0))) > 1e-6:\n",
    "            last_spend_year = yr\n",
    "            break\n",
    "    if last_spend_year is None:\n",
    "        last_spend_idx = -1\n",
    "    else:\n",
    "        last_spend_idx = fy.index(last_spend_year)\n",
    "\n",
    "    # Funding/net paths from the model\n",
    "    val_by_id = val_override or {}\n",
    "    funding_M_raw: List[float] = []\n",
    "    if val_by_id and hasattr(M, \"funding\"):\n",
    "        for t in range(ny):\n",
    "            funding_M_raw.append(_val(val_by_id, M.funding[t]) / SPEND_SCALE)\n",
    "    else:\n",
    "        funding_M_raw = funding_target_M.tolist()[:ny]\n",
    "\n",
    "    dividend_M_raw: List[float] = []\n",
    "    if val_by_id and hasattr(M, \"dividend\"):\n",
    "        for t in range(ny):\n",
    "            dividend_M_raw.append(_val(val_by_id, M.dividend[t]) / SPEND_SCALE)\n",
    "    else:\n",
    "        dividend_M_raw = [0.0] * ny\n",
    "\n",
    "    net_M_raw: List[float] = []\n",
    "    if val_by_id and hasattr(M, \"net\"):\n",
    "        for t in range(ny):\n",
    "            net_M_raw.append(_val(val_by_id, M.net[t]) / SPEND_SCALE)\n",
    "    else:\n",
    "        net_prev = 0.0\n",
    "        for t in range(ny):\n",
    "            yr = fy[t]\n",
    "            spend = float(df_sp.loc[\"Total Spend\", yr])\n",
    "            net_now = net_prev + funding_M_raw[t] - spend - dividend_M_raw[t]\n",
    "            net_M_raw.append(net_now)\n",
    "            net_prev = net_now\n",
    "\n",
    "    # For reporting: after the last year with spend, envelope & funding & net are zero.\n",
    "    funding_M: List[float] = []\n",
    "    net_M: List[float] = []\n",
    "    env_M_plot: List[float] = []\n",
    "    div_M: List[float] = []\n",
    "    for t in range(ny):\n",
    "        if last_spend_idx >= 0 and t <= last_spend_idx:\n",
    "            fund = funding_M_raw[t]\n",
    "            netv = net_M_raw[t]\n",
    "            env = funding_target_M[t]\n",
    "            div = dividend_M_raw[t]\n",
    "        else:\n",
    "            fund = 0.0\n",
    "            netv = 0.0\n",
    "            env = 0.0\n",
    "            div = 0.0\n",
    "        funding_M.append(fund)\n",
    "        net_M.append(netv)\n",
    "        env_M_plot.append(env)\n",
    "        div_M.append(div)\n",
    "\n",
    "    # Cash-flow table (M)\n",
    "    cash_rows = []\n",
    "    for t in range(ny):\n",
    "        yr = fy[t]\n",
    "        spend = float(df_sp.loc[\"Total Spend\", yr])\n",
    "        env = env_M_plot[t]\n",
    "        fund = funding_M[t]\n",
    "        opening_net = 0.0 if t == 0 else net_M[t - 1]\n",
    "        closing_net = net_M[t]\n",
    "        div = div_M[t]\n",
    "        cash_rows.append(\n",
    "            dict(\n",
    "                Year=yr,\n",
    "                Envelope=env,\n",
    "                Funding=fund,\n",
    "                OpeningNet=opening_net,\n",
    "                Spend=spend,\n",
    "                Dividend=div,\n",
    "                ClosingNet=closing_net,\n",
    "                OpeningCash=max(opening_net, 0.0),\n",
    "                OpeningDebt=max(-opening_net, 0.0),\n",
    "                ClosingCash=max(closing_net, 0.0),\n",
    "                ClosingDebt=max(-closing_net, 0.0),\n",
    "            )\n",
    "        )\n",
    "    df_cash = pd.DataFrame(cash_rows)\n",
    "\n",
    "    # Benefits by year / proj-dimension\n",
    "    dims = list(kernels_by_dim.keys())\n",
    "    Tstore = ny\n",
    "    for (v, s) in sel.keys():\n",
    "        for d in dims:\n",
    "            ker = kernels_by_dim.get(d, {}).get(v, [])\n",
    "            if ker:\n",
    "                Tstore = max(Tstore, s + len(ker))\n",
    "    fy_store = cal_years(Tstore)\n",
    "\n",
    "    ben_total_by_dim_store: Dict[str, np.ndarray] = {\n",
    "        d: np.zeros(Tstore, float) for d in dims\n",
    "    }\n",
    "    proj_dim_year_store: Dict[Tuple[str, str], np.ndarray] = {\n",
    "        (p, d): np.zeros(Tstore, float) for d in dims for p in projects.keys()\n",
    "    }\n",
    "\n",
    "    for (v, s) in sel.keys():\n",
    "        for d in dims:\n",
    "            ker = kernels_by_dim[d].get(v, [])\n",
    "            for k, f in enumerate(ker):\n",
    "                t = s + k\n",
    "                if 0 <= t < Tstore:\n",
    "                    ben_total_by_dim_store[d][t] += float(f)\n",
    "                    proj_dim_year_store[(v, d)][t] += float(f)\n",
    "\n",
    "    df_ben_year = pd.DataFrame(\n",
    "        {\"Year\": fy_store, **{d: ben_total_by_dim_store[d] for d in dims}}\n",
    "    )\n",
    "\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [list(projects.keys()), dims],\n",
    "        names=[\"Project\", \"Dimension\"],\n",
    "    )\n",
    "    df_ben_proj_dim_year = pd.DataFrame(0.0, index=idx, columns=fy_store)\n",
    "    for (p, d), vec in proj_dim_year_store.items():\n",
    "        df_ben_proj_dim_year.loc[(p, d), :] = vec\n",
    "\n",
    "    disc = np.array([(1.0 + benefit_rate) ** t for t in range(ny)], float)\n",
    "    pv_by_dim: Dict[str, float] = {\n",
    "        d: float(np.sum(ben_total_by_dim_store[d][:ny] / disc)) for d in dims\n",
    "    }\n",
    "    pv_by_proj_dim = pd.DataFrame(0.0, index=idx, columns=[\"PV\"])\n",
    "    for (p, d) in idx:\n",
    "        vec_full = df_ben_proj_dim_year.loc[(p, d)].to_numpy(dtype=float)\n",
    "        pv_by_proj_dim.loc[(p, d), \"PV\"] = float(np.sum(vec_full[:ny] / disc))\n",
    "\n",
    "    total_pv = pv_by_dim.get(\n",
    "        \"Total\",\n",
    "        float(np.sum([pv_by_dim[d] for d in dims if d != \"Total\"])),\n",
    "    )\n",
    "\n",
    "    # Diagnostics: no-debt + closing net (raw)\n",
    "    try:\n",
    "        val_for_diag = val_override or {id(var): float(var.X) for var in M.net}\n",
    "        assert_and_log_invariants(M, funding_target_M, val_for_diag, label=tag)\n",
    "        net_list = [_val(val_for_diag, M.net[t]) / SPEND_SCALE for t in range(M.Tn)]\n",
    "        diag_caps: Dict[str, Any] = {\n",
    "            \"closing_net_M_raw\": float(net_list[-1]),\n",
    "            \"max_net_M_raw\": float(max(net_list) if net_list else 0.0),\n",
    "        }\n",
    "    except AssertionError as e:\n",
    "        diag_caps = {\"assertion_error\": str(e)}\n",
    "\n",
    "    # Final relative gap (fraction + percent)\n",
    "    gap_now = float(gap_override) if gap_override is not None else _best_gap(M.m)\n",
    "    gap_pct = gap_now * 100.0 if gap_now is not None else None\n",
    "\n",
    "    out: Dict[str, Any] = dict(\n",
    "        status=status_text,\n",
    "        objective=primary_dim,\n",
    "        created_at=_now_stamp(),\n",
    "        scenario=scenario_name,\n",
    "        primary_dim=primary_dim,\n",
    "        schedule=df_sched,\n",
    "        spend=df_sp,\n",
    "        cash_flow=df_cash,\n",
    "        envelope=pd.DataFrame({\"Year\": fy, \"Envelope\": env_M_plot}),\n",
    "        benefits_by_year=df_ben_year,\n",
    "        benefits_by_project_dimension_by_year=df_ben_proj_dim_year,\n",
    "        pv_by_dimension=pv_by_dim,\n",
    "        pv_total=total_pv,\n",
    "        gap=gap_now,\n",
    "        gap_pct=gap_pct,\n",
    "        best={\"pv\": total_pv, \"gap\": gap_now, \"gap_pct\": gap_pct},\n",
    "        pv_by_project_and_dimension=pv_by_proj_dim,\n",
    "        calendar=dict(start_fy=START_FY, years=ny),\n",
    "        meta=dict(\n",
    "            full_envelope_M=float(funding_target_M[0])\n",
    "            if len(funding_target_M) > 0\n",
    "            else 0.0,\n",
    "            taper_years=0,\n",
    "            backlog_weight=BACKLOG_WEIGHT,\n",
    "            pv_weight=PV_WEIGHT,\n",
    "            net_cap_tiers=PIECEWISE_CAP_TIERS,\n",
    "            run_id=RUN_ID,\n",
    "        ),\n",
    "    )\n",
    "    if extra_diag:\n",
    "        out.setdefault(\"diagnostic\", {}).update(extra_diag)\n",
    "    if diag_caps:\n",
    "        out.setdefault(\"diagnostic\", {}).update(diag_caps)\n",
    "\n",
    "    fn = CACHE / f\"{(PKL_PREFIX or '')}{tag}.pkl\"\n",
    "    if str(fn).endswith(\"}.pkl\"):\n",
    "        fn = Path(str(fn)[:-5] + \".pkl\")\n",
    "    pkl_save(fn, out)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Cross‑buffer registry\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "_BEST_PV_BY_ENV: Dict[Tuple[str, str, float], float] = {}\n",
    "_BEST_SEL_BY_ENV: Dict[Tuple[str, str, float], Dict[Tuple[str, int], int]] = {}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Objective construction\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def _set_weighted_objective(\n",
    "    M: CoptSpendMatchMO,\n",
    "    expr_primary_pv: co.LinExpr,\n",
    "    *,\n",
    "    tag: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "        Minimise  BACKLOG_WEIGHT * ∑ backlog[t]\n",
    "                + ∑ (Weight_i * Excess_Tier_i[t])  <-- Piecewise Penalty\n",
    "                - PV_WEIGHT      * PV\n",
    "    \"\"\"\n",
    "\n",
    "    obj_backlog = BACKLOG_WEIGHT * M.annual_backlog_sum\n",
    "    obj_excess = M.tier_penalties_expr\n",
    "    obj_pv = expr_primary_pv * PV_WEIGHT\n",
    "\n",
    "    combined_obj = obj_backlog + obj_excess - obj_pv\n",
    "    M.m.setObjective(combined_obj, COPT.MINIMIZE)\n",
    "\n",
    "    _log(\n",
    "        f\"[{tag}] Objective: MIN(\"\n",
    "        f\" {BACKLOG_WEIGHT:.1f} * Backlog\"\n",
    "        f\" + PiecewiseExcessPenalty\"\n",
    "        f\" - {PV_WEIGHT:.1e} * PV )\"\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class Incumbent:\n",
    "    sel: Dict[Tuple[str, int], int]\n",
    "    pv: float\n",
    "    max_net_balance: float      # maximum net balance over the horizon (M)\n",
    "    annual_backlog_sum: float   # total backlog over the horizon (M)\n",
    "    val_by_id: Dict[int, float]\n",
    "    model: CoptSpendMatchMO\n",
    "    gap: Optional[float]\n",
    "\n",
    "def build_total_model(\n",
    "    variants: Dict[str, dict],\n",
    "    allowed: Dict[str, List[int]],\n",
    "    funding_target_S: np.ndarray,\n",
    "    Tfine: int,\n",
    "    taper_start_idx: int,\n",
    "    coeff_total_fine_int: Dict[Tuple[str, int], int],\n",
    "    total_floor_target: Optional[float],\n",
    "    is_whitelist_model: bool,\n",
    "    *,\n",
    "    relax_binaries: bool = False,\n",
    ") -> CoptSpendMatchMO:\n",
    "    M = CoptSpendMatchMO(\n",
    "        variants,\n",
    "        allowed,\n",
    "        funding_target_S,\n",
    "        Tfine,\n",
    "        taper_start_idx,\n",
    "        spend_by_year={v: variants[v][\"spend\"] for v in variants},\n",
    "        max_starts_per_year=MAX_STARTS_PER_FY,\n",
    "        is_whitelist_model=is_whitelist_model,\n",
    "        name=\"MO_SPEND_MATCH\",\n",
    "        relax_binaries=relax_binaries,\n",
    "    )\n",
    "\n",
    "    expr_tot_pv = M.obj_expr(coeff_total_fine_int, cache_key=\"TOT_PV\")\n",
    "\n",
    "    if total_floor_target is not None:\n",
    "        floor_target = total_floor_target - max(\n",
    "            MONO_ABS_EPS, MONO_REL_EPS * abs(total_floor_target)\n",
    "        )\n",
    "        M.add_floor(expr_tot_pv, floor_target, name=\"mono_total_floor\")\n",
    "\n",
    "    _set_weighted_objective(M, expr_tot_pv, tag=\"TOTAL\")\n",
    "    return M\n",
    "\n",
    "def eval_incumbent(\n",
    "    M: CoptSpendMatchMO,\n",
    "    val_by_id: Dict[int, float],\n",
    "    coeff_total_fine: Dict[Tuple[str, int], float],\n",
    ") -> Incumbent:\n",
    "    sel = selection_from_values(M.x, val_by_id)\n",
    "    pv = pv_from_selection(coeff_total_fine, sel)\n",
    "\n",
    "    net_vals_M = [_val(val_by_id, M.net[t]) / SPEND_SCALE for t in range(M.Tn)]\n",
    "    max_net_balance = max(net_vals_M) if net_vals_M else 0.0\n",
    "\n",
    "    backlog_vals_M = [_val(val_by_id, M.backlog[t]) / SPEND_SCALE for t in range(M.Tn)]\n",
    "    annual_backlog_sum = sum(backlog_vals_M)\n",
    "\n",
    "    gap = _best_gap(M.m)\n",
    "    return Incumbent(\n",
    "        sel=sel,\n",
    "        pv=pv,\n",
    "        max_net_balance=max_net_balance,\n",
    "        annual_backlog_sum=annual_backlog_sum,\n",
    "        val_by_id=val_by_id,\n",
    "        model=M,\n",
    "        gap=gap,\n",
    "    )\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Orchestrator (Piecewise)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def orchestrate_total(\n",
    "    variants: Dict[str, dict],\n",
    "    allowed_fine: Dict[str, List[int]],\n",
    "    funding_target_S: np.ndarray,\n",
    "    Tfine: int,\n",
    "    taper_start_idx: int,\n",
    "    coeff_total_fine: Dict[Tuple[str, int], float],\n",
    "    coeff_total_fine_int: Dict[Tuple[str, int], int],\n",
    "    total_floor_target: Optional[float],\n",
    "    is_whitelist_model: bool,\n",
    "    *,\n",
    "    sel_seed: Optional[Dict[Tuple[str, int], int]],\n",
    "    rel_gap_target: float,\n",
    "    time_budget_s: float,\n",
    ") -> Tuple[Optional[Incumbent], Optional[float]]:\n",
    "    _log(\n",
    "        f\"[orchestrate] Building model with FIXED FUNDING + PIECEWISE SOFT CAP. \"\n",
    "        f\"Time budget: {time_budget_s:.0f}s, target gap={rel_gap_target:.4f}\"\n",
    "    )\n",
    "\n",
    "    M = build_total_model(\n",
    "        variants,\n",
    "        allowed_fine,\n",
    "        funding_target_S,\n",
    "        Tfine,\n",
    "        taper_start_idx,\n",
    "        coeff_total_fine_int,\n",
    "        total_floor_target,\n",
    "        is_whitelist_model,\n",
    "    )\n",
    "\n",
    "    if sel_seed:\n",
    "        M.add_hint_from_starts(sel_seed)\n",
    "\n",
    "    res = solve_model(\n",
    "        M.m,\n",
    "        stage=\"MAIN_SOLVE\",\n",
    "        base_time=time_budget_s,\n",
    "        rel_gap=rel_gap_target,\n",
    "    )\n",
    "\n",
    "    if not res.has_inc:\n",
    "        _log(\"[orchestrate] Solve finished with no incumbent solution.\")\n",
    "        return None, res.gap\n",
    "\n",
    "    # Extract solution values from the model\n",
    "    valmap = extract_solution_values(M)\n",
    "    if not valmap:\n",
    "        _log(\"[orchestrate] Solve failed to extract variable values.\")\n",
    "        return None, res.gap\n",
    "\n",
    "    best_inc = eval_incumbent(M, valmap, coeff_total_fine)\n",
    "    _log(\n",
    "        \"[orchestrate] Solve complete. \"\n",
    "        f\"BacklogSum: {best_inc.annual_backlog_sum:,.1f} M, \"\n",
    "        f\"MaxNetBalance: {best_inc.max_net_balance:,.1f} M, \"\n",
    "        f\"PV: {best_inc.pv:,.1f}, \"\n",
    "        f\"Gap: {best_inc.gap or float('nan'):.4%}\"\n",
    "    )\n",
    "    return best_inc, best_inc.gap\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# DIMENSION run (weighted)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "TOTAL_PV_GUARD_PCT = 85.0\n",
    "\n",
    "def weights_for_dimension(\n",
    "    primary_dim: str,\n",
    "    variants: Dict[str, dict],\n",
    "    kernels_by_dim: Dict[str, Dict[str, List[float]]],\n",
    "    r: float,\n",
    ") -> Dict[str, float]:\n",
    "    alpha = 1.0\n",
    "    beta = 0.5\n",
    "    wmin = 1.0\n",
    "    wmax = 2.0\n",
    "    eps = 1e-9\n",
    "    dims = list(kernels_by_dim.keys())\n",
    "    if primary_dim not in kernels_by_dim:\n",
    "        return {v: 1.0 for v in variants}\n",
    "\n",
    "    def pv_start0(ker: List[float], r_: float) -> float:\n",
    "        pv = 0.0\n",
    "        denom = 1.0\n",
    "        g = 1.0 + r_\n",
    "        for f in ker:\n",
    "            pv += float(f) / denom\n",
    "            denom *= g\n",
    "        return pv\n",
    "\n",
    "    pv0_primary = {\n",
    "        v: pv_start0(kernels_by_dim[primary_dim].get(v, []), r) for v in variants\n",
    "    }\n",
    "    arr = np.array(list(pv0_primary.values()))\n",
    "    order = np.argsort(arr)\n",
    "    ranks = np.empty_like(arr, dtype=float)\n",
    "    ranks[order] = np.arange(1, len(arr) + 1, dtype=float)\n",
    "    pct = {\n",
    "        k: float(max(ranks[i] / float(len(arr)), eps))\n",
    "        for i, k in enumerate(pv0_primary.keys())\n",
    "    }\n",
    "\n",
    "    others = [d for d in dims if d != primary_dim and d.lower() != \"total\"]\n",
    "    pv0_other_mean: Dict[str, float] = {}\n",
    "    for v in variants:\n",
    "        vals = [\n",
    "            pv_start0(kernels_by_dim.get(d, {}).get(v, []), r)\n",
    "            for d in others\n",
    "            if kernels_by_dim.get(d, {}).get(v)\n",
    "        ]\n",
    "        pv0_other_mean[v] = float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "    ratio: Dict[str, float] = {}\n",
    "    for v in variants:\n",
    "        denom = max(pv0_other_mean[v], eps)\n",
    "        if denom > 0:\n",
    "            ratio[v] = pv0_primary[v] / denom\n",
    "        else:\n",
    "            ratio[v] = wmax if pv0_primary[v] > 0 else 1.0\n",
    "\n",
    "    w: Dict[str, float] = {}\n",
    "    for v in variants:\n",
    "        wv = (max(ratio[v], eps)) ** alpha * (max(pct[v], eps)) ** beta\n",
    "        w[v] = float(wv)\n",
    "    m = float(np.mean(list(w.values()))) if w else 1.0\n",
    "    if m > eps:\n",
    "        w = {k: v / m for k, v in w.items()}\n",
    "\n",
    "    return {k: float(min(max(v, wmin), wmax)) for k, v in w.items()}\n",
    "\n",
    "def coeff_map_for_dim_fine_weighted(\n",
    "    dim: str,\n",
    "    variants: Dict[str, dict],\n",
    "    kernels_by_dim: Dict[str, Dict[str, List[float]]],\n",
    "    allowed_fine: Dict[str, List[int]],\n",
    "    Tfine: int,\n",
    "    disc_vec: np.ndarray,\n",
    ") -> Tuple[Dict[Tuple[str, int], float], Dict[Tuple[str, int], int]]:\n",
    "    w = weights_for_dimension(dim, variants, kernels_by_dim, BENEFIT_DISCOUNT_RATE)\n",
    "    base = coeff_map_for_dim_fine(\n",
    "        variants, kernels_by_dim.get(dim, {}), allowed_fine, Tfine, disc_vec\n",
    "    )\n",
    "    if not base:\n",
    "        return {}, {}\n",
    "    weighted = {\n",
    "        (v, s): base.get((v, s), 0.0) * float(w.get(v, 1.0)) for (v, s) in base\n",
    "    }\n",
    "    return weighted, coeff_int(weighted)\n",
    "\n",
    "def weighted_coeff_maps_for_dimension(\n",
    "    dim: str,\n",
    "    variants: Dict[str, dict],\n",
    "    kernels_by_dim: Dict[str, Dict[str, List[float]]],\n",
    "    allowed_fine: Dict[str, List[int]],\n",
    "    Tfine: int,\n",
    "    disc_vec: np.ndarray,\n",
    ") -> Tuple[Dict[Tuple[str, int], float], Dict[Tuple[str, int], int]]:\n",
    "    return coeff_map_for_dim_fine_weighted(\n",
    "        dim, variants, kernels_by_dim, allowed_fine, Tfine, disc_vec\n",
    "    )\n",
    "\n",
    "def run_dimensions_for_env(\n",
    "    ct: str,\n",
    "    sc_key: str,\n",
    "    sc_sheet: str,\n",
    "    sur_key: str,\n",
    "    plus_M: float,\n",
    "    *,\n",
    "    projects: Dict[str, dict],\n",
    "    variants: Dict[str, dict],\n",
    "    costs_input_df: pd.DataFrame,\n",
    "    ben_kernel_df: pd.DataFrame,\n",
    "    kernels_by_dim: Dict[str, Dict[str, List[float]]],\n",
    "    Tfine: int,\n",
    "    taper_start_idx: int,\n",
    "    funding_target_M: np.ndarray,\n",
    "    funding_target_S: np.ndarray,\n",
    "    allowed_fine: Dict[str, List[int]],\n",
    "    disc_vec: np.ndarray,\n",
    "    coeff_total_fine_int: Dict[Tuple[str, int], int],\n",
    "    total_best_sel: Dict[Tuple[str, int], int],\n",
    "    total_best_pv: float,\n",
    "    is_whitelist_model: bool,\n",
    "    tot_model_for_fallback: Optional[CoptSpendMatchMO],\n",
    "    tot_valmap_for_fallback: Optional[Dict[int, float]],\n",
    "    prev_dim_floors: Optional[Dict[str, float]] = None,\n",
    "    dims_filter: Optional[Iterable[str]] = None,\n",
    ") -> Dict[str, float]:\n",
    "    prev_dim_floors = dict(prev_dim_floors or {})\n",
    "    dims_all = [d for d in kernels_by_dim.keys() if d.lower() != \"total\"]\n",
    "    if dims_filter is not None:\n",
    "        dims = [d for d in dims_all if d in set(dims_filter)]\n",
    "    else:\n",
    "        dims = dims_all\n",
    "\n",
    "    if not dims:\n",
    "        _log(\" [DIM] No weighted-dimension runs requested.\")\n",
    "        return prev_dim_floors\n",
    "\n",
    "    total_floor = float(total_best_pv) * (TOTAL_PV_GUARD_PCT / 100.0)\n",
    "\n",
    "    for dim in dims:\n",
    "        tag_dim = (\n",
    "            f\"{ct.replace(' ','').replace('-', '')}_{sc_key}_{sur_key}_pm{int(plus_M)}_\"\n",
    "            f\"{dim_short(dim)}\"\n",
    "        )\n",
    "        _log(f\" [DIM] {dim} (weighted) with Total-guard ≥ {total_floor:,.6f}\")\n",
    "\n",
    "        coeff_dim_w_f, coeff_dim_w_int = weighted_coeff_maps_for_dimension(\n",
    "            dim, variants, kernels_by_dim, allowed_fine, Tfine, disc_vec\n",
    "        )\n",
    "\n",
    "        if not coeff_dim_w_int:\n",
    "            if tot_model_for_fallback is not None:\n",
    "                dump_pickle_full(\n",
    "                    tot_model_for_fallback,\n",
    "                    tag_dim,\n",
    "                    projects=projects,\n",
    "                    variants=variants,\n",
    "                    costs_input_df=costs_input_df,\n",
    "                    ben_kernel_df=ben_kernel_df,\n",
    "                    kernels_by_dim=kernels_by_dim,\n",
    "                    benefit_rate=BENEFIT_DISCOUNT_RATE,\n",
    "                    scenario_name=sc_key,\n",
    "                    primary_dim=f\"{dim} [WEIGHTED]\",\n",
    "                    Tfine=Tfine,\n",
    "                    funding_target_M=funding_target_M,\n",
    "                    sel_override=total_best_sel,\n",
    "                    val_override=tot_valmap_for_fallback,\n",
    "                    gap_override=_best_gap(tot_model_for_fallback.m),\n",
    "                    status_override=\"OK_SUBOPT_NOCOEFF\",\n",
    "                    extra_diag={\n",
    "                        \"note\": \"dimension has zero coefficients; reported Total solution\"\n",
    "                    },\n",
    "                )\n",
    "            prev_dim_floors[dim] = pv_from_selection(coeff_dim_w_f, total_best_sel)\n",
    "            continue\n",
    "\n",
    "        Md = CoptSpendMatchMO(\n",
    "            variants,\n",
    "            allowed_fine,\n",
    "            funding_target_S,\n",
    "            Tfine,\n",
    "            taper_start_idx,\n",
    "            spend_by_year={v: variants[v][\"spend\"] for v in variants},\n",
    "            max_starts_per_year=MAX_STARTS_PER_FY,\n",
    "            is_whitelist_model=is_whitelist_model,\n",
    "            name=f\"MO_DIM_{dim_short(dim)}\",\n",
    "        )\n",
    "        Md.add_hint_from_starts(total_best_sel)\n",
    "\n",
    "        expr_dim_pv = Md.obj_expr(\n",
    "            coeff_dim_w_int, cache_key=f\"DIM_{dim_short(dim)}\"\n",
    "        )\n",
    "\n",
    "        # Total PV guard\n",
    "        expr_tot_guard = Md.obj_expr(\n",
    "            coeff_total_fine_int, cache_key=\"TOT_GUARD\"\n",
    "        )\n",
    "        Md.add_floor(\n",
    "            expr_tot_guard,\n",
    "            total_floor - max(MONO_ABS_EPS, MONO_REL_EPS * abs(total_floor)),\n",
    "            name=\"dim_total_floor\",\n",
    "        )\n",
    "\n",
    "        _set_weighted_objective(\n",
    "            Md, expr_dim_pv, tag=f\"DIM_{dim_short(dim)}\"\n",
    "        )\n",
    "\n",
    "        base_time = EFFORT[OPTIMISATION_PROFILE][\"MO\"]\n",
    "        rel_gap = EFFORT[OPTIMISATION_PROFILE][\"REL_GAP\"]\n",
    "        res = solve_model(\n",
    "            Md.m,\n",
    "            stage=f\"DIM[{dim_short(dim)}]\",\n",
    "            base_time=base_time,\n",
    "            rel_gap=rel_gap,\n",
    "        )\n",
    "\n",
    "        if _has_incumbent(Md.m):\n",
    "            valmap = extract_solution_values(Md)\n",
    "            if valmap:\n",
    "                assert_and_log_invariants(\n",
    "                    Md, funding_target_M, valmap, label=tag_dim\n",
    "                )\n",
    "                dump_pickle_full(\n",
    "                    Md,\n",
    "                    tag_dim,\n",
    "                    projects=projects,\n",
    "                    variants=variants,\n",
    "                    costs_input_df=costs_input_df,\n",
    "                    ben_kernel_df=ben_kernel_df,\n",
    "                    kernels_by_dim=kernels_by_dim,\n",
    "                    benefit_rate=BENEFIT_DISCOUNT_RATE,\n",
    "                    scenario_name=sc_key,\n",
    "                    primary_dim=f\"{dim} [WEIGHTED]\",\n",
    "                    Tfine=Tfine,\n",
    "                    funding_target_M=funding_target_M,\n",
    "                    sel_override=selection_from_values(Md.x, valmap),\n",
    "                    val_override=valmap,\n",
    "                    gap_override=res.gap,\n",
    "                )\n",
    "            else:\n",
    "                _log(f\"[DIM] {dim} solve OK but value extraction failed.\")\n",
    "                if tot_model_for_fallback is not None:\n",
    "                    dump_pickle_full(\n",
    "                        tot_model_for_fallback,\n",
    "                        tag_dim,\n",
    "                        projects=projects,\n",
    "                        variants=variants,\n",
    "                        costs_input_df=costs_input_df,\n",
    "                        ben_kernel_df=ben_kernel_df,\n",
    "                        kernels_by_dim=kernels_by_dim,\n",
    "                        benefit_rate=BENEFIT_DISCOUNT_RATE,\n",
    "                        scenario_name=sc_key,\n",
    "                        primary_dim=f\"{dim} [WEIGHTED]\",\n",
    "                        Tfine=Tfine,\n",
    "                        funding_target_M=funding_target_M,\n",
    "                        sel_override=total_best_sel,\n",
    "                        val_override=tot_valmap_for_fallback,\n",
    "                        gap_override=_best_gap(tot_model_for_fallback.m),\n",
    "                        status_override=\"OK_SUBOPT_VALFAIL\",\n",
    "                        extra_diag={\n",
    "                            \"note\": \"dimension solver ok but val extract failed; \"\n",
    "                            \"reported Total solution\"\n",
    "                        },\n",
    "                    )\n",
    "        else:\n",
    "            _log(f\"[DIM] {dim} solve failed to find incumbent.\")\n",
    "            if tot_model_for_fallback is not None:\n",
    "                dump_pickle_full(\n",
    "                    tot_model_for_fallback,\n",
    "                    tag_dim,\n",
    "                    projects=projects,\n",
    "                    variants=variants,\n",
    "                    costs_input_df=costs_input_df,\n",
    "                    ben_kernel_df=ben_kernel_df,\n",
    "                    kernels_by_dim=kernels_by_dim,\n",
    "                    benefit_rate=BENEFIT_DISCOUNT_RATE,\n",
    "                    scenario_name=sc_key,\n",
    "                    primary_dim=f\"{dim} [WEIGHTED]\",\n",
    "                    Tfine=Tfine,\n",
    "                    funding_target_M=funding_target_M,\n",
    "                    sel_override=total_best_sel,\n",
    "                    val_override=tot_valmap_for_fallback,\n",
    "                    gap_override=_best_gap(tot_model_for_fallback.m),\n",
    "                    status_override=\"OK_SUBOPT_NOSOLVE\",\n",
    "                    extra_diag={\n",
    "                        \"note\": \"dimension solver yielded no incumbent; \"\n",
    "                        \"reported Total solution\"\n",
    "                    },\n",
    "                )\n",
    "    return prev_dim_floors\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Helpers for dimension names\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "_DIM_SHORT: Dict[str, str] = {\n",
    "    \"Total\": \"TOT\",\n",
    "    \"Healthy and safe people\": \"HSP\",\n",
    "    \"Inclusive Access\": \"INC\",\n",
    "    \"Environmental Sustainability\": \"ENV\",\n",
    "    \"Economic Prosperity\": \"ECO\",\n",
    "    \"Resilience and Security\": \"RES\",\n",
    "}\n",
    "\n",
    "def dim_short(dim: str) -> str:\n",
    "    if dim in _DIM_SHORT:\n",
    "        return _DIM_SHORT[dim]\n",
    "    toks = re.findall(r\"[A-Za-z0-9]+\", dim or \"\")\n",
    "    return (\"\".join(t[:3] for t in toks)[:8] or \"DIM\").upper()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Run combo\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def get_funding_envelope(\n",
    "    Tfine: int,\n",
    "    base_M: float,\n",
    "    taper_start_from_end: int,\n",
    ") -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Build the envelope *capacity* path (M) and return:\n",
    "        funding_M[t]  – max available funding in year t (constant base_M)\n",
    "        taper_start_idx – dummy index (no taper; set to Tfine)\n",
    "    \"\"\"\n",
    "    funding_M = np.full(Tfine, float(base_M), dtype=float)\n",
    "    taper_start_idx = Tfine  # no taper region; kept for compatibility\n",
    "    return funding_M, taper_start_idx\n",
    "\n",
    "def run_combo(\n",
    "    ct: str,\n",
    "    sc_key: str,\n",
    "    sc_sheet: str,\n",
    "    sur_key: str,\n",
    "    baseline_surplus_M: float,\n",
    "    plus_M: float,\n",
    "    prev_dim_floors: Optional[Dict[str, float]] = None,\n",
    "    prev_best_sel: Optional[Dict[Tuple[str, int], int]] = None,\n",
    "):\n",
    "    projects_all, variants_all, costs_input_df = load_costs(ct)\n",
    "\n",
    "    variants, forced_exact, is_whitelist_model = apply_forced_rules(\n",
    "        variants_all, FORCED_START\n",
    "    )\n",
    "    projects = {p: projects_all[p] for p in variants.keys() if p in projects_all}\n",
    "\n",
    "    # --- PROCESS MIN START YEARS ---\n",
    "    min_start_norm = {norm(k): v for k, v in (MIN_START_YEAR or {}).items()}\n",
    "    min_start_exact: Dict[str, int] = {}\n",
    "    for v in variants:\n",
    "        n = norm(v)\n",
    "        if n in min_start_norm:\n",
    "            min_start_exact[v] = min_start_norm[n]\n",
    "    # -------------------------------\n",
    "\n",
    "    benef_df, ben_kernel_df = load_benefits(sc_sheet)\n",
    "    dims_order, kernels_by_dim = map_benefit_kernels(benef_df, variants)\n",
    "    total_key = \"Total\"\n",
    "\n",
    "    include_norm = {norm(k): bool(v) for k, v in (DIMENSION_INCLUSIONS or {}).items()}\n",
    "    dims_to_run = [\n",
    "        d\n",
    "        for d in kernels_by_dim.keys()\n",
    "        if d.lower() != \"total\" and include_norm.get(norm(d), False)\n",
    "    ]\n",
    "\n",
    "    full_envelope_M = float(baseline_surplus_M) + float(plus_M)\n",
    "\n",
    "    # Fixed horizon across buffers so that feasibility is comparable and\n",
    "    # the monotone PV guard makes sense.\n",
    "    Tfine = TFIXED\n",
    "\n",
    "    tot_cost = float(sum(sum(meta[\"spend\"]) for meta in variants.values()))\n",
    "    _log(\n",
    "        f\" Fixed Horizon: TotCost={tot_cost:,.0f}M, Env={full_envelope_M:,.0f}M/yr \"\n",
    "        f\"-> Years={Tfine}\"\n",
    "    )\n",
    "    _log(f\" PV window: {START_FY}→{START_FY + Tfine - 1} (Tfine={Tfine})\")\n",
    "\n",
    "    funding_target_M, taper_start_idx = get_funding_envelope(\n",
    "        Tfine,\n",
    "        full_envelope_M,\n",
    "        taper_start_from_end=TAPER_YEARS,\n",
    "    )\n",
    "    funding_target_S = np.array(\n",
    "        [iround(m, SPEND_SCALE) for m in funding_target_M],\n",
    "        dtype=float,\n",
    "    )\n",
    "    _log(\n",
    "        f\" Envelope capacity: up to {full_envelope_M:,.0f} M per year \"\n",
    "        f\"(chosen as needed).\"\n",
    "    )\n",
    "\n",
    "    tag_tot = (\n",
    "        f\"{ct.replace(' ','').replace('-', '')}_{sc_key}_{sur_key}_pm{int(plus_M)}_\"\n",
    "        f\"{_DIM_SHORT['Total']}\"\n",
    "    )\n",
    "\n",
    "    total_funding_M = float(np.sum(funding_target_M))\n",
    "\n",
    "    if is_whitelist_model and (tot_cost > total_funding_M + 1e-9):\n",
    "        msg = (\n",
    "            f\"[WHITELIST] Total project spend {tot_cost:,.1f} M exceeds *total* \"\n",
    "            f\"funding capacity {total_funding_M:,.1f} M. Scenario infeasible.\"\n",
    "        )\n",
    "        print(\" ×\", msg)\n",
    "        fn = CACHE / f\"{(PKL_PREFIX or '')}{tag_tot}_noSol.pkl\"\n",
    "        pkl_save(\n",
    "            fn,\n",
    "            {\n",
    "                \"status\": \"NoSolve\",\n",
    "                \"reason\": \"mass-balance infeasible (whitelist)\",\n",
    "                \"detail\": msg,\n",
    "                \"objective\": \"Total\",\n",
    "                \"created_at\": _now_stamp(),\n",
    "                \"gap\": None,\n",
    "                \"gap_pct\": None,\n",
    "            },\n",
    "        )\n",
    "        return None, prev_dim_floors, prev_best_sel\n",
    "\n",
    "    allowed_fine = allowed_starts_fine(\n",
    "        variants, forced_exact, min_start_exact, Tfine\n",
    "    )\n",
    "    missing = [p for p in variants if not allowed_fine.get(p)]\n",
    "    if missing:\n",
    "        fn = CACHE / f\"{(PKL_PREFIX or '')}{tag_tot}_noSol.pkl\"\n",
    "        pkl_save(\n",
    "            fn,\n",
    "            {\n",
    "                \"status\": \"NoSolve\",\n",
    "                \"reason\": f\"no allowed starts for {missing[:5]}\",\n",
    "                \"diagnostic\": {\"phase\": \"screen\", \"Tfine\": Tfine},\n",
    "                \"objective\": \"Total\",\n",
    "                \"created_at\": _now_stamp(),\n",
    "                \"gap\": None,\n",
    "                \"gap_pct\": None,\n",
    "            },\n",
    "        )\n",
    "        return None, prev_dim_floors, prev_best_sel\n",
    "\n",
    "    disc_vec = np.array(\n",
    "        [(1.0 + BENEFIT_DISCOUNT_RATE) ** t for t in range(Tfine)],\n",
    "        dtype=float,\n",
    "    )\n",
    "    coeff_total_fine = coeff_map_for_dim_fine(\n",
    "        variants, kernels_by_dim[total_key], allowed_fine, Tfine, disc_vec\n",
    "    )\n",
    "    coeff_total_fine_int = coeff_int(coeff_total_fine)\n",
    "\n",
    "    sel_hint = greedy_warm_start(\n",
    "        variants,\n",
    "        allowed_fine,\n",
    "        Tfine,\n",
    "        funding_target_M,\n",
    "        MAX_STARTS_PER_FY,\n",
    "        forced_exact,\n",
    "        coeff_total_fine,\n",
    "        reuse_sel=prev_best_sel,\n",
    "    )\n",
    "\n",
    "    prev_env = max(\n",
    "        [\n",
    "            e\n",
    "            for (ctk, sck, e) in _BEST_PV_BY_ENV.keys()\n",
    "            if ctk == ct and sck == sc_key and e < full_envelope_M\n",
    "        ],\n",
    "        default=None,\n",
    "    )\n",
    "    total_floor_target = None\n",
    "    if ENFORCE_MONOTONE_PV_ACROSS_BUFFERS and prev_env is not None:\n",
    "        prev_best = _BEST_PV_BY_ENV[(ct, sc_key, prev_env)]\n",
    "        total_floor_target = prev_best\n",
    "\n",
    "    prof_effort = EFFORT[OPTIMISATION_PROFILE]\n",
    "    best_inc, final_gap = orchestrate_total(\n",
    "        variants,\n",
    "        allowed_fine,\n",
    "        funding_target_S,\n",
    "        Tfine,\n",
    "        taper_start_idx,\n",
    "        coeff_total_fine,\n",
    "        coeff_total_fine_int,\n",
    "        total_floor_target,\n",
    "        is_whitelist_model,\n",
    "        sel_seed=sel_hint,\n",
    "        rel_gap_target=prof_effort[\"REL_GAP\"],\n",
    "        time_budget_s=float(prof_effort[\"MO\"]),\n",
    "    )\n",
    "\n",
    "    if best_inc is None or best_inc.model is None:\n",
    "        fn = CACHE / f\"{(PKL_PREFIX or '')}{tag_tot}_noSol.pkl\"\n",
    "        pkl_save(\n",
    "            fn,\n",
    "            {\n",
    "                \"status\": \"NoSolve\",\n",
    "                \"reason\": \"no incumbent with piecewise cap\",\n",
    "                \"objective\": \"Total\",\n",
    "                \"created_at\": _now_stamp(),\n",
    "                \"diagnostic\": {\n",
    "                    \"note\": \"No feasible solution found.\",\n",
    "                },\n",
    "                \"gap\": None,\n",
    "                \"gap_pct\": None,\n",
    "            },\n",
    "        )\n",
    "        return None, prev_dim_floors, prev_best_sel\n",
    "\n",
    "    extra_diag = {\n",
    "        \"orchestrated_gap\": f\"{(final_gap if final_gap is not None else float('nan')):.4%}\",\n",
    "        \"net_cap_tiers\": str(PIECEWISE_CAP_TIERS),\n",
    "    }\n",
    "\n",
    "    assert_and_log_invariants(\n",
    "        best_inc.model, funding_target_M, best_inc.val_by_id, label=tag_tot\n",
    "    )\n",
    "\n",
    "    dump_pickle_full(\n",
    "        best_inc.model,\n",
    "        tag_tot,\n",
    "        projects=projects,\n",
    "        variants=variants,\n",
    "        costs_input_df=costs_input_df,\n",
    "        ben_kernel_df=ben_kernel_df,\n",
    "        kernels_by_dim=kernels_by_dim,\n",
    "        benefit_rate=BENEFIT_DISCOUNT_RATE,\n",
    "        scenario_name=sc_key,\n",
    "        primary_dim=\"Total\",\n",
    "        Tfine=Tfine,\n",
    "        funding_target_M=funding_target_M,\n",
    "        sel_override=best_inc.sel,\n",
    "        val_override=best_inc.val_by_id,\n",
    "        gap_override=best_inc.gap,\n",
    "        extra_diag=extra_diag,\n",
    "    )\n",
    "\n",
    "    best_sel_for_next = best_inc.sel\n",
    "    valmap_for_fallback = best_inc.val_by_id\n",
    "\n",
    "    _BEST_PV_BY_ENV[(ct, sc_key, full_envelope_M)] = pv_from_selection(\n",
    "        coeff_total_fine, best_sel_for_next\n",
    "    )\n",
    "    if best_sel_for_next:\n",
    "        _BEST_SEL_BY_ENV[(ct, sc_key, full_envelope_M)] = best_sel_for_next\n",
    "\n",
    "    # Weighted-dimension runs\n",
    "    include_norm = {norm(k): bool(v) for k, v in (DIMENSION_INCLUSIONS or {}).items()}\n",
    "    dims_to_run = [\n",
    "        d\n",
    "        for d in kernels_by_dim.keys()\n",
    "        if d.lower() != \"total\" and include_norm.get(norm(d), False)\n",
    "    ]\n",
    "\n",
    "    disc_vec = np.array(\n",
    "        [(1.0 + BENEFIT_DISCOUNT_RATE) ** t for t in range(Tfine)],\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    prev_dims = run_dimensions_for_env(\n",
    "        ct,\n",
    "        sc_key,\n",
    "        sc_sheet,\n",
    "        sur_key,\n",
    "        plus_M,\n",
    "        projects=projects,\n",
    "        variants=variants,\n",
    "        costs_input_df=costs_input_df,\n",
    "        ben_kernel_df=ben_kernel_df,\n",
    "        kernels_by_dim=kernels_by_dim,\n",
    "        Tfine=Tfine,\n",
    "        taper_start_idx=taper_start_idx,\n",
    "        funding_target_M=funding_target_M,\n",
    "        funding_target_S=funding_target_S,\n",
    "        allowed_fine=allowed_fine,\n",
    "        disc_vec=disc_vec,\n",
    "        coeff_total_fine_int=coeff_total_fine_int,\n",
    "        total_best_sel=best_sel_for_next,\n",
    "        total_best_pv=pv_from_selection(\n",
    "            coeff_total_fine, best_sel_for_next\n",
    "        ),\n",
    "        is_whitelist_model=is_whitelist_model,\n",
    "        tot_model_for_fallback=best_inc.model,\n",
    "        tot_valmap_for_fallback=valmap_for_fallback,\n",
    "        prev_dim_floors=prev_dim_floors,\n",
    "        dims_filter=dims_to_run,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        pv_from_selection(coeff_total_fine, best_sel_for_next),\n",
    "        prev_dims,\n",
    "        best_sel_for_next,\n",
    "    )\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# Driver\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def main() -> None:\n",
    "    random.seed(SOLVER_SEED_DEFAULT)\n",
    "    np.random.seed(SOLVER_SEED_DEFAULT)\n",
    "\n",
    "    global _BEST_PV_BY_ENV, _BEST_SEL_BY_ENV\n",
    "    _BEST_PV_BY_ENV.clear()\n",
    "    _BEST_SEL_BY_ENV.clear()\n",
    "\n",
    "    print(\n",
    "        f\"CFG: START_FY={START_FY} FINAL_YEAR={FINAL_YEAR} \"\n",
    "        f\"PV_WINDOW={TFIXED}y MAX_STARTS/FY={MAX_STARTS_PER_FY}\"\n",
    "    )\n",
    "    eff = EFFORT[OPTIMISATION_PROFILE]\n",
    "    print(\n",
    "        f\"Effort: {OPTIMISATION_PROFILE} → \"\n",
    "        f\"{{'MO': {eff['MO']}, 'REL_GAP': {eff['REL_GAP']}}}\"\n",
    "    )\n",
    "    print(\"NEW MODEL (v94.14 - Hybrid):\")\n",
    "    print(\"  - FIXED FUNDING: funding[t] == Envelope.\")\n",
    "    print(\"  - DIVIDEND (Restricted): Only allowed at end-of-life (y[t+1]=0).\")\n",
    "    print(\"  - PIECEWISE SOFT CAP: Tiers 12%/15%/20%.\")\n",
    "    print(\"  - ALL PROJECTS: sum(x) == 1.0 (Mandatory Selection).\")\n",
    "    print(\"  - FIXED PV HORIZON: Tfine = TFIXED.\")\n",
    "    print(\"  - PROFILE-DEPENDENT SOLVE:\")\n",
    "    print(\"      fast/balanced → single-phase (v94.11 style)\")\n",
    "    print(\"      thorough      → 2-phase (Probe + Verify + Victory Lap)\")\n",
    "    print(\"      ultra         → 3-phase (Probe + Verify + Victory Lap + Grind)\\n\")\n",
    "\n",
    "    if FORCED_START:\n",
    "        print(f\"FORCED_START: {len(FORCED_START)} rules are active.\")\n",
    "    if MIN_START_YEAR:\n",
    "        print(f\"MIN_START_YEAR: {len(MIN_START_YEAR)} constraint rules are active.\")\n",
    "\n",
    "    dims_incl_str = \", \".join(\n",
    "        [k for k, v in DIMENSION_INCLUSIONS.items() if k.lower() != \"total\" and v]\n",
    "    )\n",
    "    print(\n",
    "        f\"Dimension inclusions (non-Total): \"\n",
    "        f\"{dims_incl_str if dims_incl_str else 'None'}\"\n",
    "    )\n",
    "    print(f\"RUN_ID: {RUN_ID}\\n\")\n",
    "\n",
    "    for ct in COST_TYPES_RUN:\n",
    "        print(f\"\\n=== COST: {ct} ===\")\n",
    "        for sc_key, sc_sheet in BENEFIT_SCENARIOS.items():\n",
    "            print(f\">> Scenario {sc_key} (sheet {sc_sheet})\")\n",
    "            prev_sel: Optional[Dict[Tuple[str, int], int]] = None\n",
    "            prev_dims: Dict[str, float] = {}\n",
    "            envs_sorted = sorted(\n",
    "                SURPLUS_OPTIONS_M.items(), key=lambda kv: kv[1]\n",
    "            )\n",
    "\n",
    "            for sur_key, baseM in envs_sorted:\n",
    "                print(f\" -- Base Funding {sur_key} = {baseM:.0f} M p.a. --\")\n",
    "                for plus in sorted(PLUSMINUS_LEVELS_M):\n",
    "                    print(f\" Running... FULL={baseM+plus:,.0f} M\")\n",
    "                    out = run_combo(\n",
    "                        ct,\n",
    "                        sc_key,\n",
    "                        sc_sheet,\n",
    "                        sur_key,\n",
    "                        baseM,\n",
    "                        plus,\n",
    "                        prev_dim_floors=prev_dims,\n",
    "                        prev_best_sel=prev_sel,\n",
    "                    )\n",
    "                    if out is not None:\n",
    "                        tot_pv, prev_dims, prev_sel = out\n",
    "\n",
    "    print(\"\\n✓ Done. Pickles are under:\", CACHE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        main()\n",
    "    finally:\n",
    "        print(f\"\\nRun-time: {time.time()-t0:.1f}s → {CACHE}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
